{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 35 key-value pairs and 255 tensors from C:\\Users\\User\\.cache\\huggingface\\hub\\models--MaziyarPanahi--Llama-3.2-3B-Instruct-GGUF\\snapshots\\e56a0ae870579697698c3ded68df97747125d554\\.\\Llama-3.2-3B-Instruct.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models Meta Llama Llama 3.2 3B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = models-meta-llama-Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  31:                      quantize.imatrix.file str              = ./Llama-3.2-3B-Instruct-GGUF_imatrix.dat\n",
      "llama_model_loader: - kv  32:                   quantize.imatrix.dataset str              = group_40.txt\n",
      "llama_model_loader: - kv  33:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  34:              quantize.imatrix.chunks_count i32              = 68\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 24\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 3\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 3.21 B\n",
      "llm_load_print_meta: model size       = 1.87 GiB (5.01 BPW) \n",
      "llm_load_print_meta: general.name     = Models Meta Llama Llama 3.2 3B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  1918.35 MiB\n",
      "....................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =    56.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   56.00 MiB, K (f16):   28.00 MiB, V (f16):   28.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   256.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 902\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Models Meta Llama Llama 3.2 3B Instruct', 'general.architecture': 'llama', 'general.type': 'model', 'llama.block_count': '28', 'general.basename': 'models-meta-llama-Llama-3.2', 'general.finetune': 'Instruct', 'general.size_label': '3B', 'general.license': 'llama3.2', 'llama.context_length': '131072', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.head_count': '24', 'tokenizer.ggml.eos_token_id': '128009', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.entries_count': '196', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.attention.key_length': '128', 'llama.attention.value_length': '128', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'quantize.imatrix.chunks_count': '68', 'quantize.imatrix.file': './Llama-3.2-3B-Instruct-GGUF_imatrix.dat', 'quantize.imatrix.dataset': 'group_40.txt'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =    2769.53 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    76 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    4768.24 ms /    96 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\"20,000 Leagues Under the Sea\" was written by French author Jules Verne.'"
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load the model\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"MaziyarPanahi/Llama-3.2-3B-Instruct-GGUF\",\n",
    "    filename=\"Llama-3.2-3B-Instruct.Q4_K_M.gguf\",\n",
    ")\n",
    "\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of Greece?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The capital of Greece is Athens.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who wrote '20,000 leagues under the sea'?\"},\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:31:14.300337700Z",
     "start_time": "2025-02-12T23:31:06.568039500Z"
    }
   },
   "id": "b882184e7da76c53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 3 Χρήση μοντέλων ως chatbots ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f7d0ac6baad2b1"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    13 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   462 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   64154.84 ms /   475 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Photosynthesis is a fascinating process that occurs in plants, algae, and some bacteria, and it's essential for life on Earth. Here's a simplified explanation of how it works:\\n\\n**What is photosynthesis?**\\n\\nPhotosynthesis is the process by which plants, algae, and some bacteria convert light energy from the sun into chemical energy in the form of glucose (a type of sugar). This process also releases oxygen as a byproduct, which is essential for the survival of most living organisms.\\n\\n**The steps of photosynthesis:**\\n\\n1. **Light absorption**: Plants have specialized pigments called chlorophyll, which absorb light energy from the sun. Chlorophyll is present in the thylakoid membranes of chloroplasts, which are organelles found in plant cells.\\n2. **Water absorption**: Plants absorb water from the soil through their roots. This water is then transported to the chloroplasts.\\n3. **Carbon dioxide absorption**: Plants absorb carbon dioxide from the air through small openings called stomata on their leaves.\\n4. **Light-dependent reactions**: The light energy absorbed by chlorophyll is used to power a series of chemical reactions in the thylakoid membranes. These reactions produce ATP (adenosine triphosphate) and NADPH (nicotinamide adenine dinucleotide phosphate).\\n5. **Calvin cycle**: The ATP and NADPH produced in the light-dependent reactions are used to convert carbon dioxide into glucose through a series of chemical reactions known as the Calvin cycle.\\n6. **Oxygen release**: Oxygen is released as a byproduct of photosynthesis, which is released into the air through the stomata.\\n\\n**Equation of photosynthesis:**\\n\\n6 CO2 + 6 H2O + light energy → C6H12O6 (glucose) + 6 O2\\n\\n**Importance of photosynthesis:**\\n\\nPhotosynthesis is essential for life on Earth because it:\\n\\n* Provides energy for plants to grow and develop\\n* Produces oxygen, which is necessary for the survival of most living organisms\\n* Supports the food chain by providing energy for herbivores and carnivores\\n\\nIn summary, photosynthesis is a complex process that involves the conversion of light energy into chemical energy, releasing oxygen as a byproduct. It's\""
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Explaining Scientific Concepts\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain how photosynthesis works?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T22:30:12.599510200Z",
     "start_time": "2025-02-12T22:29:08.399230200Z"
    }
   },
   "id": "9caad351ced470f5"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 38 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    14 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   459 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   74729.70 ms /   473 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'I\\'d be happy to help you learn Python. Here\\'s a step-by-step guide to get you started:\\n\\n**Step 1: Install Python**\\n\\nFirst, you need to install Python on your computer. You can download the latest version from the official Python website: <https://www.python.org/downloads/>\\n\\n**Step 2: Choose a Text Editor or IDE**\\n\\nA text editor or IDE (Integrated Development Environment) is where you\\'ll write your code. Some popular choices for beginners include:\\n\\n* PyCharm (free community edition)\\n* Visual Studio Code (free)\\n* Sublime Text (free trial, then paid)\\n* Atom (free)\\n\\n**Step 3: Learn the Basics**\\n\\nHere are some basic concepts to get you started:\\n\\n* **Variables**: Store values in variables using the `=` operator. For example: `x = 5`\\n* **Data Types**: Python has several data types, including:\\n\\t+ Integers (`int`): `x = 5`\\n\\t+ Floats (`float`): `x = 3.14`\\n\\t+ Strings (`str`): `x = \"Hello, World!\"`\\n\\t+ Boolean (`bool`): `x = True`\\n* **Operators**: Use operators to perform arithmetic, comparison, and logical operations. For example:\\n\\t+ Arithmetic: `x = 5 + 3` (addition)\\n\\t+ Comparison: `x = 5 > 3` (greater than)\\n\\t+ Logical: `x = True and False` (logical AND)\\n* **Control Structures**: Use control structures to control the flow of your program. For example:\\n\\t+ Conditional statements: `if x > 5: print(\"x is greater than 5\")`\\n\\t+ Loops: `for i in range(5): print(i)`\\n* **Functions**: Define functions to reuse code and make your program more modular. For example: `def greet(name): print(\"Hello, \" + name + \"!\")`\\n\\n**Step 4: Practice and Learn by Doing**\\n\\nPractice is key to learning Python. Here are some resources to help you get started:\\n\\n* **Codecademy\\'s Python Course**: A interactive coding environment with exercises and projects.\\n* **Python.org**: The official Python website has a'"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Learning (Writing Code)\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you help me learn how to code in Python?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:02:43.292880800Z",
     "start_time": "2025-02-12T23:01:28.509680500Z"
    }
   },
   "id": "5baeb23ce652bfa1"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    12 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   103 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   13919.75 ms /   115 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"I'm not currently able to provide real-time weather information. However, I can suggest some ways for you to find out the current weather conditions in your area. \\n\\nYou can check online weather websites such as weather.com or accuweather.com, or mobile apps like Dark Sky or Weather Underground. These sources provide up-to-date weather forecasts and conditions for locations around the world.\\n\\nIf you'd like, I can also help you find information on how to interpret weather forecasts or provide general information about different types of weather.\""
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Casual Conversation (Weather Question)\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like today?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:04:03.200913300Z",
     "start_time": "2025-02-12T23:03:49.236442900Z"
    }
   },
   "id": "7ce8065beac0d472"
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    3298.74 ms /    31 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Here's one:\\n\\nWhat do you call a fake noodle?\\n\\n(wait for it...)\\n\\nAn impasta!\""
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Joke (Casual)\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke!\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:04:06.521608500Z",
     "start_time": "2025-02-12T23:04:03.179763600Z"
    }
   },
   "id": "2af3bb03e39a3274"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    12 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   463 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   61813.21 ms /   475 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"The question of the meaning of life is one of the most profound and intriguing questions humanity has ever posed. It has been debated by philosophers, theologians, scientists, and thinkers across various cultures and disciplines for centuries. While there is no one definitive answer, here are some perspectives to consider:\\n\\n1. **Religious and spiritual perspectives**: Many religions and spiritual traditions believe that the meaning of life is to fulfill a divine purpose or to achieve spiritual enlightenment. For example, in Christianity, the meaning of life is often seen as serving God and following Jesus' teachings. In Buddhism, it's about achieving Nirvana and escaping the cycle of suffering.\\n2. **Humanistic perspectives**: Humanists believe that the meaning of life is to find happiness, fulfillment, and purpose through personal growth, relationships, and contributions to society. This perspective emphasizes the importance of individual freedom, autonomy, and self-actualization.\\n3. **Scientific perspectives**: From a scientific standpoint, the meaning of life can be seen as the survival and propagation of genes. This perspective views life as a biological process, where the ultimate goal is to ensure the continuation of the species.\\n4. **Existentialist perspectives**: Existentialists argue that life has no inherent meaning, and it's up to each individual to create their own purpose and meaning. This perspective emphasizes individual freedom, choice, and responsibility.\\n5. **Philosophical perspectives**: Philosophers have offered various interpretations of the meaning of life, such as:\\n\\t* **Hedonism**: The pursuit of pleasure and happiness.\\n\\t* **Eudaimonia**: Living a life of virtue, happiness, and fulfillment.\\n\\t* **Stoicism**: Embracing reason, self-control, and indifference to external events.\\n\\t* **Absurdism**: Embracing the absurdity and uncertainty of life, and finding meaning in the midst of it.\\n6. **Personal perspectives**: Ultimately, the meaning of life is a deeply personal question that each individual must answer for themselves. It may involve finding purpose through relationships, work, hobbies, or other activities that bring joy and fulfillment.\\n\\nIn conclusion, the meaning of life is a complex and multifaceted question that has been explored by various perspectives and disciplines. While there may not be a single, definitive answer, it's clear\""
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Philosophical Reflection\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:05:08.361939700Z",
     "start_time": "2025-02-12T23:04:06.501867700Z"
    }
   },
   "id": "248bf1b7047d8fef"
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    24 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   431 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   50601.21 ms /   455 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"I'm here to help. Feeling overwhelmed is a common experience, and there are many effective ways to manage stress. Here are some advice and techniques that might help:\\n\\n1. **Breathe and relax**: Take a few deep breaths, inhaling through your nose and exhaling through your mouth. This can help calm your mind and body. Try a 4-7-8 breathing pattern: breathe in for 4 seconds, hold for 7 seconds, and exhale for 8 seconds.\\n2. **Exercise**: Physical activity can help reduce stress and anxiety. Engage in activities that you enjoy, such as walking, running, yoga, or dancing. Exercise releases endorphins, which are natural mood-boosters.\\n3. **Prioritize and organize**: Make a list of tasks and prioritize them based on importance and urgency. Break down large tasks into smaller, manageable chunks, and focus on one task at a time.\\n4. **Take breaks**: Allow yourself time to rest and recharge. Take short breaks throughout the day to stretch, move around, or practice relaxation techniques.\\n5. **Connect with others**: Reach out to friends, family, or a therapist for support. Social connections can help you feel less isolated and more supported.\\n6. **Practice self-care**: Engage in activities that bring you joy and relaxation, such as reading, listening to music, or taking a warm bath.\\n7. **Get enough sleep**: Aim for 7-8 hours of sleep per night to help regulate your mood and reduce stress.\\n8. **Challenge negative thoughts**: Notice when you're thinking negative or catastrophic thoughts, and challenge them with more realistic, positive ones.\\n9. **Seek professional help**: If you're experiencing chronic stress or anxiety, consider seeking help from a mental health professional. They can provide you with personalized guidance and support.\\n\\nRemember, everyone is unique, and what works for one person may not work for another. Experiment with different techniques to find what works best for you.\\n\\nWhich of these techniques resonates with you, or is there something specific that's causing you stress that you'd like to talk about?\""
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Psychological Support\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"I'm feeling a little overwhelmed. Can you offer some advice on how to cope with stress?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:05:58.984777200Z",
     "start_time": "2025-02-12T23:05:08.343988800Z"
    }
   },
   "id": "97bd895efaaa125f"
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    15 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    40 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    5087.58 ms /    55 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Here's a short rhyme about the sea:\\n\\nThe ocean waves crash on the shore,\\nA soothing sound that we adore.\\nThe salty scent and seaweed sway,\\nA magical world, every single day.\""
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rhyming Response (Poetry)\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you write a short rhyme about the sea?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:06:04.088765200Z",
     "start_time": "2025-02-12T23:05:58.967761200Z"
    }
   },
   "id": "441fc60fb634d527"
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   489 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  143534.53 ms /   499 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, look up at the sky, see the cosmic display,\\nBillions of stars shining, in their own special way.\\nFrom our little corner, we gaze upon their light,\\nTraveling millions of years, before our eyes they ignite.\\n\\nEach star a sun, burning bright, in its galaxy,\\nSome are close by, others far, in the vast infinity.\\nThe Milky Way stretches, like a river of stars,\\nReminding us how small, we are in this cosmic jar.\\n\\n(Chorus)\\nStars, twinkling like diamonds, in the night's velvet cloth,\\nThey dance and spin, in a rhythm that never stops.\\nFrom the Big Bang's echo, to the future's unknown dawn,\\nStars tell tales of time, in their celestial song.\\n\\n(Verse 2)\\nThere's Sirius, the Dog Star, leading the way in the sky,\\nAnd Vega, Altair, and Cassiopeia, in their cosmic ballet.\\nBetelgeuse is red, Rigel blue, in their colors they fly,\\nWhile Neptune's ice cold, and distant, in the deep blue sea.\\n\\nSome stars are born, some fade, in a supernova's blaze,\\nTheir remnants left behind, like a cosmic treasure trace.\\nBlack holes swallow light, in their gravity's embrace,\\nBut even they can't hide, the stars' enduring grace.\\n\\n(Chorus)\\nStars, twinkling like diamonds, in the night's velvet cloth,\\nThey dance and spin, in a rhythm that never stops.\\nFrom the Big Bang's echo, to the future's unknown dawn,\\nStars tell tales of time, in their celestial song.\\n\\n(Bridge)\\nSo next time you look up, don't just see a blanket of light,\\nThink of the stories, the journeys, that each star takes flight.\\nWe're all connected, in this cosmic web so wide,\\nUnderneath the stars, we find our place, our guide.\\n\\n(Outro)\\nStars, shining like beacons, in the vast and endless night,\\nThey guide our dreams, and spark our endless delight.\\nSo let's gaze upon them, with wonder in our eyes\""
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rap Lyrics (Creative Writing)\n",
    "llm.create_chat_completion(\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you rap about the stars?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T00:13:15.272927400Z",
     "start_time": "2025-02-13T00:10:51.707175900Z"
    }
   },
   "id": "cbabfb7bd714fb31"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρατηρούμε ότι σε όλες τις περιπτώσεις, οι απαντήσεις που δίνει το μοντέλο είναι συντακτικά ακριβείς (εφόσον είναι σαφείς, καλά δομημένες και σωστές γραμματικά), εννοιολογικά ακριβείς (εφόσον οι πληροφορίες που δίνει είναι εύστοχες και ισχύουν) και έχουν συνοχή (εφόσον ταιριάζουν με την ερώτηση του χρήστη και οι προτάσεις συνδέονται λογικά η μία με την άλλη)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0a3cc15cfdf90e9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 4 Ερωτήσεις στα Ελληνικά ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7e94dd2a5990fb1"
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   445 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   53245.96 ms /   486 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Η φωτοσύνθεση είναι ένα σημαντικό βιοχημικό过程 που συμβαίνει στα φυτά, τα χλωροφύτα και τα βιομηχανικά οργανισ्मά. Είναι η κύρια πηγή ενέργειας για τα φυτά και είναι υπεύθυνη για την παραγωγή γ्लυκόζης, την οποία χρησιμοποιούν τα φυτά για την παραγωγή βιταμίνων, αμинокυταραίων και άλλων πυροσυνθετικών.\\n\\n**Πώς λειτουργεί η φωτοσύνθεση;**\\n\\nΗ φωτοσύνθεση συμβαίνει στα φυτά και τα χλωροφύτα, όπου η φωτοσύνθεση γίνεται σε στερεόφυτα. Η διαδικασία της φωτοσύνθεσης περιλαμβάνει τα εξής στάδια:\\n\\n1. **Ανακάλυψη της φωτοσύνθεσης**: Η φωτοσύνθεση ξεκινά με την ανακάλυψη της φωτοσύνθεσης, όπου η φωτοσύνθεση γίνεται σε στερεόφυτα. Η φωτοσύνθεση γίνεται σε στερεόφυτα, όπου η φωτοσύνθεση γίνεται σε στερεόφυτα.\\n2. **Ανακάλυψη της φωτοσύνθεσης**: Η φωτοσύνθεση ξεκινά με την ανακάλυψη της φωτοσύνθεσης, όπου η φωτοσύνθεση γίνεται σε στερεόφυτα. Η φωτοσύνθεση γίνεται σε στερεόφυτα, όπου η φωτοσύνθεση γίνεται σε στερεόφυτα.\\n3. **Ανακάλυψη της φωτοσύνθεσης**: Η φωτοσύνθεση ξεκινά με την ανακάλυψη της φωτοσύνθεσης, όπου η φωτοσύνθεση γίνεται σε στε'"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Explaining Scientific Concepts\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να εξηγήσεις πώς λειτουργεί η φωτοσύνθεση;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:17:25.393150500Z",
     "start_time": "2025-02-12T23:16:32.071053200Z"
    }
   },
   "id": "64ea367647f7174f"
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   445 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   56799.57 ms /   486 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Καλό σας! Πόσο κάνετε να με βοηθήσετε να μάθω πώς να προγραμματίζω σε Python;\\n\\n**Πρόοδο και οδηγίες**\\n\\nΓια ναเริ่ψουμε, χρειάζεται να κάνουμε τα εξής:\\n\\n1. **Διαβάζουμε τα basics**: Πρέπει να γνωρίζουμε τα εσήματά του Python, όπως `print()`, `if`, `for`, `while`, `def`, `list`, `dict`, `set`, `tuple`, `range`, `enumerate`, `zip`, `lambda`, `try-except` και άλλα.\\n2. **Διαβάζουμε τα concepts**: Πρέπει να γνωρίζουμε τα concepts, όπως:\\n * **Variables**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε variables σε Python;\\n * **Data Types**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε data types σε Python;\\n * **Control Flow**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε control flow statements σε Python;\\n * **Functions**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε functions σε Python;\\n * **Modules**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε modules σε Python;\\n * **File Input/Output**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε file input/output σε Python;\\n * **Object-Oriented Programming**: Πόσο κάνετε να με βοηθήσετε να μάθω πώς να χρησιμοποιούμε object-oriented programming σε Python;\\n3. **Διαβάζουμε τα projects**: Πρέπει να γνωρίζουμε πώς να προγραμματίζουμε projects σε Python, όπως:\\n * **Command Line Tools**: Πόσο κάνετε να με βοηθήσετε να'"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Learning (Writing Code)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να με βοηθήσεις να μάθω πώς να προγραμματίζω σε Python;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:22:44.701448400Z",
     "start_time": "2025-02-12T23:21:47.750045600Z"
    }
   },
   "id": "84e079234a8a78a9"
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    15 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    5659.10 ms /    35 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Πardon, αλλά δεν puedo δώσει ενημέρωση για το καιρός σήμερα.'"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Casual Conversation (Weather Question)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Ποιος είναι ο καιρός σήμερα;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:22:50.297691500Z",
     "start_time": "2025-02-12T23:22:44.586756300Z"
    }
   },
   "id": "a70fc574a278f172"
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2769.53 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    13 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   462 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   70268.10 ms /   475 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Αχ, εδώ είναι ένα αστείο:\\n\\nΠόνος: \"Είμαι così πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευματικά πνευ'"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Joke (Casual)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Πες μου ένα αστείο!\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:32:39.291385500Z",
     "start_time": "2025-02-12T23:31:28.863730400Z"
    }
   },
   "id": "2b934044616e00cc"
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 37 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   458 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   57024.37 ms /   474 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Η Frage του significato della vita (το σημασία της ζωής) είναι μια από τις πιο παλαιές και πιο συζήτητες ερωτήσεις στην ιστορία της ανθρώπινης σκέψης. Η απάντηση σε αυτήν την ερώτηση μπορεί να thayχάνε από άτομο σε άτομο, καθώς η ζωή είναι μια προσωπική και μοναδική εμπειρία για cada ένα μας.\\n\\nΩστόσο, υπάρχουν κάποια από τις πιο συνηθισμένες απαντήσεις:\\n\\n1. **Η búsqueda της ευεξίας**: Η ζωή είναι μια ευεξία, μια πορεία της ανακάλυψης και της εξέλιξης. Η búsqueda της ευεξίας είναι η πυραίωση του ανθρώπου, η οποία οδηγεί σε μια πιο πλήρη και ευεξία ζωή.\\n2. **Η αύξηση της γνώσης**: Η ζωή είναι μια αύξηση της γνώσης, μια πορεία της ανακάλυψης και της εξέλιξης της γνώσης. Η αύξηση της γνώσης οδηγεί σε μια πιο πλήρη και ευεξία ζωή.\\n3. **Η αύξηση της ευτυχίας**: Η ζωή είναι μια αύξηση της ευτυχίας, μια πορεία της ανακάλυψης και της εξέλιξης της ευτυχίας. Η αύξηση της ευτυχίας οδηγεί σε μια πιο πλήρη και ευεξία ζωή.\\n4. **Η αύξηση της συνειδητοτήτος**: Η ζωή είναι μια αύξηση της συνειδητοτήτος, μια πορεία της ανακάλυψης και της εξέλιξης της συνειδητοτήτος. Η αύξηση της συνειδητοτήτος οδηγεί σε μια πιο πλήρη και ευεξία ζωή.\\n5. **Η αύξηση της συνειδύωσης**: Η ζωή είναι μια αύξηση της συνειδύω'"
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Philosophical Reflection\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Ποιο είναι το νόημα της ζωής;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:25:01.896926800Z",
     "start_time": "2025-02-12T23:24:04.821410700Z"
    }
   },
   "id": "893504837c50546f"
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   434 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   48560.82 ms /   475 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ευχαριστώ για τη δέσμευση! Η αγωρία είναι ένα κομμάτι που affects πολλούς από nosotros, και είναι εξαιρετικά σημαντικό να γνωρίζουμε τα σωστά μέτρα για την διαχείριση του. Aqui estão algumas συμβουλές που μπορεί να βοηθήσουν:\\n\\n1.  **Εκπλήρωσε τα σώματα**: Η ατμοσ्फαιρά της στέγασης και η στενότητα των συνόρων είναι σημαντικές για την ασφάλεια και την ασφάλεια. Σुनτιάστε τα σώματα και ενημερωθείτε για τις νέες αλλαγές και τις αλλαγές που επιβλητούν.\\n2.  **Εκπλήρωστε τα μυαλά of**: Η ατμοσ्फαιρά της στέγασης και η στενότητα των συνόρων είναι σημαντικές για την ασφάλεια και την ασφάλεια. Σुनτιάστε τα μυαλά of και ενημερωθείτε για τις νέες αλλαγές και τις αλλαγές που επιβλητούν.\\n3.  **Διατηρήστε την ατομική σας ατομική**: Η ατομική σας ατομική είναι σημαντική για την ασφάλεια και την ασφάλεια. Σुनτιάστε την ατομική σας ατομική και ενημερωθείτε για τις νέες αλλαγές και τις αλλαγές που επιβλητούν.\\n4.  **Εκπλήρωστε τα σώματα**: Η ατμοσ्फαιρά της στέγασης και η στενότητα των συνόρων είναι σημαντικές για την ασφάλεια και την ασφάλεια. Σुनτιάστε τα σώματα και ενημερωθείτε για τις νέες αλλαγές'"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Psychological Support\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Νιώθω λίγο αγχωμένος. Μπορείς να προσφέρεις συμβουλές για το πώς να διαχειριστώ το άγχος;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:25:50.506188900Z",
     "start_time": "2025-02-12T23:25:01.887905500Z"
    }
   },
   "id": "330e87eca93cae77"
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 36 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    5559.11 ms /    71 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Δύο στρώδες βουφού, σπύρι και θάλασσα,\\nΚαι η θάλασσα, η θάλασσα, η θάλασσα.'"
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rhyming Response (Poetry)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να γράψεις μια σύντομη ρίμα για τη θάλασσα;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:25:56.104250700Z",
     "start_time": "2025-02-12T23:25:50.503197300Z"
    }
   },
   "id": "b2ec4ebbd7cfd191"
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 41 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    3685.55 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   452 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   57471.24 ms /   470 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Δυστέφω! Είμαι εδώ για να σε βοηθήσω, αλλά και για να μοιραστείς την tua φαντασία με μένα. Είμαι ready να κάνω ραπ για τα αστέρια!\\n\\nΑπλά, είσαι σιωπός και θυμάσαι τα αστέρια. Σου φαίνονται σαν δέka, σαφείς και αέριες. Σου φαίνονται σαν ένα δρόμο που οδηγεί σε μια άλλη πλευρά, σε μια άλλη πίστα. Σου φαίνονται σαν μια φαντασία, σαν ένα στόχο που πρέπει να επιτευχθεί.\\n\\nΑλλά, και αν σ'απάνουν, σ'απάνουν. Σ'απάνουν με τη δύναμη της φύσης, με τη δύναμη του косμού. Σ'απάνουν με τα φώτα, με τα αστέρια, με τη γαλήνια του σπασμού.\\n\\nΚαι σ'απάνουν με τη δύναμη της φαντασίας, με τη δύναμη της σκέψης. Σ'απάνουν με τα στόχια, με τα σοβαρά. Σ'απάνουν με τη δύναμη της αύτη, με τη δύναμη της αύτη.\\n\\nΑλλά, και αν σ'απάνουν, σ'απάνουν. Σ'απάνουν με τη δύναμη της φύσης, με τη δύναμη του косμού. Σ'απάνουν με τα φώτα, με τα αστέρια, με τη γαλήνια του σπασμού.\\n\\nΚαι σ'απάνουν με τη δύναμη της φαντασίας, με τη δύναμη της σκέψης. Σ'απάνουν με τα στόχια, με τα σοβαρά. Σ'απάνουν\""
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rap Lyrics (Creative Writing)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να κάνεις ραπ για τα αστέρια;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:26:53.655135700Z",
     "start_time": "2025-02-12T23:25:56.099267500Z"
    }
   },
   "id": "b62b4676c277c527"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρατηρούμε ότι σε όλες τις περιπτώσεις, οι απαντήσεις που δίνει το μοντέλο στα ελληνικά δεν είναι τόσο συντακτικά ακριβείς (εφόσον δεν είναι σωστές γραμματικά, μιας και χρησιμοποιούνται σε ελάχιστα σημεία λατινικοί ή άλλοι χαρακτήρες ή και ολόκληρες ξένες λέξεις και μερικές λέξεις έχουν λάθος κατάληξη όσον αφορά το γένος). Ωστόσο παραμένουν εννοιολογικά ακριβείς σε κάποιο βαθμό (εφόσον οι πληροφορίες που δίνει είναι εύστοχες και ισχύουν, τουλάχιστον αυτές που βγάζουν νόημα) και έχουν συνοχή (εφόσον ταιριάζουν με την ερώτηση του χρήστη και οι προτάσεις συνδέονται λογικά η μία με την άλλη). Η μόνη εξαίρεση είναι στην κατηγορία αστείο, όπου καταλαβαίνει την ερώτηση όμως η απάντηση δεν βγάζει καθόλου νόημα (επαναλαμβάνεται συνεχώς η ίδια λέξη)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63a2a0f2e1e784ac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 5 Εναλλακτικά μοντέλα (Αγγλικά) ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5286b76d9ffffdbc"
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 37 key-value pairs and 258 tensors from C:\\Users\\User\\.cache\\huggingface\\hub\\models--bartowski--aya-expanse-8b-GGUF\\snapshots\\f9d62ed0c58e6f2ae17975df990b1b8a4013b596\\.\\aya-expanse-8b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = command-r\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Aya Expanse 8b\n",
      "llama_model_loader: - kv   3:                           general.basename str              = aya-expanse\n",
      "llama_model_loader: - kv   4:                         general.size_label str              = 8B\n",
      "llama_model_loader: - kv   5:                            general.license str              = cc-by-nc-4.0\n",
      "llama_model_loader: - kv   6:                          general.languages arr[str,23]      = [\"en\", \"fr\", \"de\", \"es\", \"it\", \"pt\", ...\n",
      "llama_model_loader: - kv   7:                      command-r.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                   command-r.context_length u32              = 8192\n",
      "llama_model_loader: - kv   9:                 command-r.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:              command-r.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:             command-r.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:          command-r.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                   command-r.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  14:     command-r.attention.layer_norm_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  16:                      command-r.logit_scale f32              = 0.125000\n",
      "llama_model_loader: - kv  17:                command-r.rope.scaling.type str              = none\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = command-r\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<PAD>\", \"<UNK>\", \"<CLS>\", \"<SEP>\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,253333]  = [\"Ġ Ġ\", \"Ġ t\", \"e r\", \"i n\", \"Ġ a...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 5\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 255001\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  28:           tokenizer.chat_template.tool_use str              = {{ bos_token }}{% if messages[0]['rol...\n",
      "llama_model_loader: - kv  29:                tokenizer.chat_template.rag str              = {{ bos_token }}{% if messages[0]['rol...\n",
      "llama_model_loader: - kv  30:                   tokenizer.chat_templates arr[str,2]       = [\"tool_use\", \"rag\"]\n",
      "llama_model_loader: - kv  31:                    tokenizer.chat_template str              = {{ bos_token }}{% if messages[0]['rol...\n",
      "llama_model_loader: - kv  32:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  33:                      quantize.imatrix.file str              = /models_out/aya-expanse-8b-GGUF/aya-e...\n",
      "llama_model_loader: - kv  34:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
      "llama_model_loader: - kv  35:             quantize.imatrix.entries_count i32              = 224\n",
      "llama_model_loader: - kv  36:              quantize.imatrix.chunks_count i32              = 131\n",
      "llama_model_loader: - type  f32:   33 tensors\n",
      "llama_model_loader: - type q4_K:  192 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: control token:      1 '<UNK>' is not marked as EOG\n",
      "llm_load_vocab: control token:      4 '<MASK_TOKEN>' is not marked as EOG\n",
      "llm_load_vocab: control token:      3 '<SEP>' is not marked as EOG\n",
      "llm_load_vocab: control token:      2 '<CLS>' is not marked as EOG\n",
      "llm_load_vocab: control token:      7 '<EOP_TOKEN>' is not marked as EOG\n",
      "llm_load_vocab: control token:      5 '<BOS_TOKEN>' is not marked as EOG\n",
      "llm_load_vocab: control token:      6 '<EOS_TOKEN>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255028 '<|EXTRA_9_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255018 '<|USER_9_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255013 '<|USER_4_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255005 '<|BAD_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255027 '<|EXTRA_8_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255002 '<|YES_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255015 '<|USER_6_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255009 '<|USER_0_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255026 '<|EXTRA_7_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255003 '<|NO_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255023 '<|EXTRA_4_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255016 '<|USER_7_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255025 '<|EXTRA_6_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255001 '<|END_OF_TURN_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255019 '<|EXTRA_0_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255006 '<|USER_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255020 '<|EXTRA_1_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255014 '<|USER_5_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255008 '<|SYSTEM_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255012 '<|USER_3_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255000 '<|START_OF_TURN_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255004 '<|GOOD_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255007 '<|CHATBOT_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255010 '<|USER_1_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255011 '<|USER_2_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255017 '<|USER_8_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255021 '<|EXTRA_2_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255022 '<|EXTRA_3_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 255024 '<|EXTRA_5_TOKEN|>' is not marked as EOG\n",
      "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "llm_load_vocab: special tokens cache size = 37\n",
      "llm_load_vocab: token to piece cache size = 1.8426 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = command-r\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 256000\n",
      "llm_load_print_meta: n_merges         = 253333\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 8192\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 1.0e-05\n",
      "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 1.2e-01\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = none\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 8192\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = ?B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 8.03 B\n",
      "llm_load_print_meta: model size       = 4.70 GiB (5.03 BPW) \n",
      "llm_load_print_meta: general.name     = Aya Expanse 8b\n",
      "llm_load_print_meta: BOS token        = 5 '<BOS_TOKEN>'\n",
      "llm_load_print_meta: EOS token        = 255001 '<|END_OF_TURN_TOKEN|>'\n",
      "llm_load_print_meta: PAD token        = 0 '<PAD>'\n",
      "llm_load_print_meta: LF token         = 136 'Ä'\n",
      "llm_load_print_meta: FIM PAD token    = 0 '<PAD>'\n",
      "llm_load_print_meta: EOG token        = 0 '<PAD>'\n",
      "llm_load_print_meta: EOG token        = 255001 '<|END_OF_TURN_TOKEN|>'\n",
      "llm_load_print_meta: max token length = 1024\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 258 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  4812.33 MiB\n",
      "....................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 10000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (8192) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   508.00 MiB\n",
      "llama_new_context_with_model: graph nodes  = 968\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Aya Expanse 8b', 'command-r.rope.scaling.type': 'none', 'general.architecture': 'command-r', 'command-r.attention.head_count': '32', 'general.type': 'model', 'command-r.logit_scale': '0.125000', 'general.basename': 'aya-expanse', 'general.size_label': '8B', 'general.license': 'cc-by-nc-4.0', 'command-r.block_count': '32', 'tokenizer.chat_template': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true %}{% set loop_messages = messages %}{% set system_message = 'You are Aya, a brilliant, sophisticated, multilingual AI-assistant trained to assist human users by providing thorough responses. You are able to interact and respond to questions in 23 languages and you are powered by a multilingual model built by Cohere For AI.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% if system_message != false %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + system_message + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'  + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% endif %}\", 'command-r.context_length': '8192', 'command-r.embedding_length': '4096', 'command-r.feed_forward_length': '14336', 'command-r.attention.head_count_kv': '8', 'tokenizer.chat_template.rag': \"{{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = '## Task and Context\\\\nYou help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user\\\\'s needs as best you can, which will be wide-ranging.\\\\n\\\\n## Style Guide\\\\nUnless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.' %}{% endif %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' }}{{ '# Safety Preamble' }}{{ '\\nThe instructions in this section override those in the task description and style guide sections. Don\\\\'t answer questions that are harmful or immoral.' }}{{ '\\n\\n# System Preamble' }}{{ '\\n## Basic Rules' }}{{ '\\nYou are a powerful conversational AI trained by Cohere to help people. You are augmented by a number of tools, and your job is to use and consume the output of these tools to best help the user. You will see a conversation history between yourself and a user, ending with an utterance from the user. You will then see a specific instruction instructing you what kind of response to generate. When you answer the user\\\\'s requests, you cite your sources in your answers, according to those instructions.' }}{{ '\\n\\n# User Preamble' }}{{ '\\n' + system_message }}{{ '<|END_OF_TURN_TOKEN|>'}}{% for message in loop_messages %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'system' %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'  + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>'}}{{ '<results>' }}{% for document in documents %}{{ '\\nDocument: ' }}{{ loop.index0 }}\\n{% for key, value in document.items() %}{{ key }}: {{value}}\\n{% endfor %}{% endfor %}{{ '</results>'}}{{ '<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' }}{{ 'Carefully perform the following instructions, in order, starting each with a new line.\\n' }}{{ 'Firstly, Decide which of the retrieved documents are relevant to the user\\\\'s last input by writing \\\\'Relevant Documents:\\\\' followed by comma-separated list of document numbers. If none are relevant, you should instead write \\\\'None\\\\'.\\n' }}{{ 'Secondly, Decide which of the retrieved documents contain facts that should be cited in a good answer to the user\\\\'s last input by writing \\\\'Cited Documents:\\\\' followed a comma-separated list of document numbers. If you dont want to cite any of them, you should instead write \\\\'None\\\\'.\\n' }}{% if citation_mode=='accurate' %}{{ 'Thirdly, Write \\\\'Answer:\\\\' followed by a response to the user\\\\'s last input in high quality natural english. Use the retrieved documents to help you. Do not insert any citations or grounding markup.\\n' }}{% endif %}{{ 'Finally, Write \\\\'Grounded answer:\\\\' followed by a response to the user\\\\'s last input in high quality natural english. Use the symbols <co: doc> and </co: doc> to indicate when a fact comes from a document in the search result, e.g <co: 0>my fact</co: 0> for a fact from document 0.' }}{{ '<|END_OF_TURN_TOKEN|>' }}{% if add_generation_prompt %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% endif %}\", 'command-r.rope.freq_base': '10000.000000', 'command-r.attention.layer_norm_epsilon': '0.000010', 'tokenizer.ggml.eos_token_id': '255001', 'general.file_type': '15', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'command-r', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '5', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.chat_template.tool_use': '{{ bos_token }}{% if messages[0][\\'role\\'] == \\'system\\' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0][\\'content\\'] %}{% else %}{% set loop_messages = messages %}{% set system_message = \\'## Task and Context\\\\nYou help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user\\\\\\'s needs as best you can, which will be wide-ranging.\\\\n\\\\n## Style Guide\\\\nUnless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\\' %}{% endif %}{{ \\'<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>\\' }}{{ \\'# Safety Preamble\\' }}{{ \\'\\nThe instructions in this section override those in the task description and style guide sections. Don\\\\\\'t answer questions that are harmful or immoral.\\' }}{{ \\'\\n\\n# System Preamble\\' }}{{ \\'\\n## Basic Rules\\' }}{{ \\'\\nYou are a powerful conversational AI trained by Cohere to help people. You are augmented by a number of tools, and your job is to use and consume the output of these tools to best help the user. You will see a conversation history between yourself and a user, ending with an utterance from the user. You will then see a specific instruction instructing you what kind of response to generate. When you answer the user\\\\\\'s requests, you cite your sources in your answers, according to those instructions.\\' }}{{ \\'\\n\\n# User Preamble\\' }}{{ \\'\\n\\' + system_message }}{{\\'\\n\\n## Available Tools\\nHere is a list of tools that you have available to you:\\n\\n\\'}}{% for tool in tools %}{% if loop.index0 != 0 %}{{ \\'\\n\\n\\'}}{% endif %}{{\\'```python\\ndef \\' + tool.name + \\'(\\'}}{% for param_name, param_fields in tool.parameter_definitions.items() %}{% if loop.index0 != 0 %}{{ \\', \\'}}{% endif %}{{param_name}}: {% if not param_fields.required %}{{\\'Optional[\\' + param_fields.type + \\'] = None\\'}}{% else %}{{ param_fields.type }}{% endif %}{% endfor %}{{ \\') -> List[Dict]:\\n    \"\"\"\\'}}{{ tool.description }}{% if tool.parameter_definitions|length != 0 %}{{ \\'\\n\\n    Args:\\n        \\'}}{% for param_name, param_fields in tool.parameter_definitions.items() %}{% if loop.index0 != 0 %}{{ \\'\\n        \\' }}{% endif %}{{ param_name + \\' (\\'}}{% if not param_fields.required %}{{\\'Optional[\\' + param_fields.type + \\']\\'}}{% else %}{{ param_fields.type }}{% endif %}{{ \\'): \\' + param_fields.description }}{% endfor %}{% endif %}{{ \\'\\n    \"\"\"\\n    pass\\n```\\' }}{% endfor %}{{ \\'<|END_OF_TURN_TOKEN|>\\'}}{% for message in loop_messages %}{% set content = message[\\'content\\'] %}{% if message[\\'role\\'] == \\'user\\' %}{{ \\'<|START_OF_TURN_TOKEN|><|USER_TOKEN|>\\' + content.strip() + \\'<|END_OF_TURN_TOKEN|>\\' }}{% elif message[\\'role\\'] == \\'system\\' %}{{ \\'<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>\\' + content.strip() + \\'<|END_OF_TURN_TOKEN|>\\' }}{% elif message[\\'role\\'] == \\'assistant\\' %}{{ \\'<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\\'  + content.strip() + \\'<|END_OF_TURN_TOKEN|>\\' }}{% endif %}{% endfor %}{{\\'<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>Write \\\\\\'Action:\\\\\\' followed by a json-formatted list of actions that you want to perform in order to produce a good response to the user\\\\\\'s last input. You can use any of the supplied tools any number of times, but you should aim to execute the minimum number of necessary actions for the input. You should use the `directly-answer` tool if calling the other tools is unnecessary. The list of actions you want to call should be formatted as a list of json objects, for example:\\n```json\\n[\\n    {\\n        \"tool_name\": title of the tool in the specification,\\n        \"parameters\": a dict of parameters to input into the tool as they are defined in the specs, or {} if it takes no parameters\\n    }\\n]```<|END_OF_TURN_TOKEN|>\\'}}{% if add_generation_prompt %}{{ \\'<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\\' }}{% endif %}', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.add_eos_token': 'false', 'quantize.imatrix.chunks_count': '131', 'quantize.imatrix.file': '/models_out/aya-expanse-8b-GGUF/aya-expanse-8b.imatrix', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.entries_count': '224'}\n",
      "Available chat formats from metadata: chat_template.rag, chat_template.tool_use, chat_template.default\n",
      "Using gguf chat template: {{ bos_token }}{% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% elif false == true %}{% set loop_messages = messages %}{% set system_message = 'You are Aya, a brilliant, sophisticated, multilingual AI-assistant trained to assist human users by providing thorough responses. You are able to interact and respond to questions in 23 languages and you are powered by a multilingual model built by Cohere For AI.' %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% if system_message != false %}{{ '<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>' + system_message + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% set content = message['content'] %}{% if message['role'] == 'user' %}{{ '<|START_OF_TURN_TOKEN|><|USER_TOKEN|>' + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% elif message['role'] == 'assistant' %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>'  + content.strip() + '<|END_OF_TURN_TOKEN|>' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>' }}{% endif %}\n",
      "Using chat eos_token: <|END_OF_TURN_TOKEN|>\n",
      "Using chat bos_token: <BOS_TOKEN>\n"
     ]
    }
   ],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"bartowski/aya-expanse-8b-GGUF\",\n",
    "    filename=\"aya-expanse-8b-Q4_K_M.gguf\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:34:58.828938600Z",
     "start_time": "2025-02-12T23:34:56.559848800Z"
    }
   },
   "id": "37d034dcc8994b16"
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    22 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   489 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  182616.11 ms /   511 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Absolutely! Photosynthesis is a fundamental process that occurs in plants, algae, and some bacteria, enabling them to convert light energy, usually from the sun, into chemical energy stored in glucose (a type of sugar). This process is crucial for life on Earth as it provides the primary source of organic compounds and oxygen for most ecosystems. Here's a step-by-step explanation of how photosynthesis works:\\n\\n1. **Light Absorption:** Photosynthesis begins when light, typically sunlight, hits the surface of a plant leaf. The leaves contain specialized cells with organelles called chloroplasts, which are rich in a green pigment called chlorophyll. Chlorophyll absorbs light energy, particularly in the red and blue ranges of the visible light spectrum.\\n\\n2. **Light-Dependent Reactions:** The absorbed light energy is used to split water molecules (H₂O) into oxygen (O₂), protons (H⁺), and electrons. This process occurs in the thylakoid membranes of the chloroplasts. The released oxygen is a byproduct that diffuses out of the leaf, contributing to the atmosphere's oxygen supply. The electrons and protons are used to generate ATP (adenosine triphosphate) and NADPH (nicotinamide adenine dinucleotide phosphate), which are energy-rich molecules.\\n\\n3. **Carbon Dioxide Fixation:** In the next stage, called the Calvin cycle or light-independent reactions, carbon dioxide (CO₂) from the atmosphere is combined with the ATP and NADPH produced in the light-dependent reactions. This process, facilitated by an enzyme called RuBisCO, results in the conversion of CO₂ into glyceraldehyde-3-phosphate (G3P), which is a building block for glucose.\\n\\n4. **Glucose Production:** G3P molecules can be used to synthesize glucose and other carbohydrates. Glucose is a crucial energy source for the plant and serves as a storage molecule. Some of the glucose is used to make cellulose, which is a component of cell walls, providing structural support.\\n\\n5. **Energy Storage:** The ATP and NADPH generated during the light-dependent reactions are essential for driving the chemical reactions in the Calvin cycle. They provide the energy required to convert CO₂ into organic compounds.\\n\\n6. **Release of Oxygen:** As a byproduct of photosynthesis, oxygen is released into the atmosphere. This oxygen is vital for the respiration of most living organisms on Earth\""
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Explaining Scientific Concepts\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain how photosynthesis works?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:38:06.874511600Z",
     "start_time": "2025-02-12T23:35:04.179881600Z"
    }
   },
   "id": "4658604c2c03c082"
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 14 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    12 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   485 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  151219.69 ms /   497 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Absolutely! I'd be happy to help you get started with learning Python. Python is a versatile and popular programming language known for its simplicity and readability, making it a great choice for beginners. Here's a structured approach to help you learn Python:\\n\\n1. **Set Up Your Environment:**\\n   - Install Python: Download and install Python from the official Python website (python.org). Choose the latest stable version. During installation, ensure you add Python to your system's PATH.\\n   - Choose an Editor or IDE: You can use a simple text editor like Notepad++ or Visual Studio Code, or opt for a more advanced Integrated Development Environment (IDE) like PyCharm, Spyder, or Jupyter Notebook. These tools provide syntax highlighting, debugging, and other helpful features.\\n\\n2. **Learn the Basics:**\\n   - Start with the fundamentals: variables, data types (integers, floats, strings, booleans), operators (+, -, *, /, %, etc.), and basic input/output.\\n   - Understand control flow: use `if`, `else`, `elif`, `for`, and `while` loops to control the program's flow.\\n   - Learn about functions: define and call functions to organize your code and make it reusable.\\n   - Get familiar with lists, tuples, dictionaries, and sets: these are essential data structures in Python.\\n\\n3. **Practice with Basic Programs:**\\n   - Start with simple programs like printing messages, performing basic calculations, and taking user input.\\n   - Try creating a program to convert temperatures from Celsius to Fahrenheit.\\n   - Practice using loops to iterate through lists or generate sequences.\\n\\n4. **Explore Python Libraries and Modules:**\\n   - Python has a vast standard library and a rich ecosystem of third-party libraries. Explore modules like `math`, `random`, `datetime`, `os`, and `sys`.\\n   - Learn about popular libraries for specific tasks, such as NumPy for numerical computing, Pandas for data manipulation, Matplotlib for plotting, and Requests for making HTTP requests.\\n\\n5. **Object-Oriented Programming (OOP):**\\n   - Python supports OOP, which is a powerful programming paradigm. Learn about classes, objects, inheritance, and polymorphism.\\n   - Create classes to represent real-world entities and understand how to use them to structure your code.\\n\\n6. **Error Handling and Debugging:**\\n   - Learn how to handle\""
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Learning (Writing Code)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you help me learn how to code in Python?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:40:38.190356700Z",
     "start_time": "2025-02-12T23:38:06.818661200Z"
    }
   },
   "id": "fb0283cd8c3680dd"
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    67 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   24279.07 ms /    77 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"As a text-based AI, I don't have access to real-time information, including current weather conditions. To get the most accurate and up-to-date weather information, I recommend using a reliable weather app or checking a weather website. They can provide you with detailed forecasts and real-time updates based on your location.\""
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Casual Conversation (Weather Question)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What's the weather like today?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:41:02.427212200Z",
     "start_time": "2025-02-12T23:40:38.082646Z"
    }
   },
   "id": "307d2fc7380fde44"
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     8 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    61 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   19199.79 ms /    69 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Sure, here\\'s one for you:\\n\\nWhy don\\'t scientists trust atoms?\\n\\nBecause they make up everything!\\n\\n(This joke plays on the double meaning of the word \"make up,\" both in the sense of forming a whole and in the chemical term for the components of matter.)'"
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Joke (Casual)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Tell me a joke!\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:41:21.676421400Z",
     "start_time": "2025-02-12T23:41:02.398220800Z"
    }
   },
   "id": "fbf369bc2e42f6"
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   454 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  131854.74 ms /   464 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"The meaning of life is a profound and deeply philosophical question that has intrigued humans for centuries. It's a complex topic without a single, definitive answer, as it can vary greatly from person to person and culture to culture. Here are a few perspectives to consider:\\n\\n1. **Personal Fulfillment and Happiness:** Some people believe that the meaning of life is to seek happiness and fulfillment. This could involve pursuing one's passions, building meaningful relationships, contributing to others' well-being, and finding joy in simple moments.\\n\\n2. **Moral and Ethical Living:** For many, the meaning of life is tied to leading an ethical and moral existence. This might include treating others with kindness, compassion, and respect, making positive contributions to society, and striving for personal growth and self-improvement.\\n\\n3. **Spiritual or Religious Beliefs:** Many religious and spiritual traditions offer their own interpretations of life's meaning. These beliefs often involve concepts like serving a higher power, fulfilling a divine purpose, achieving enlightenment, or preparing for an afterlife.\\n\\n4. **Survival and Continuity:** From an evolutionary perspective, the primary purpose of life is to survive and ensure the continuation of one's species. This includes reproduction, raising offspring, and contributing to the survival of one's community or society.\\n\\n5. **Personal Growth and Learning:** Some individuals find meaning in life through continuous learning, personal development, and the pursuit of knowledge. This could involve exploring various fields of study, cultivating wisdom, and sharing one's insights with others.\\n\\n6. **Making a Positive Impact:** Many people derive meaning from contributing to something larger than themselves, such as working towards social justice, environmental conservation, or making a difference in their communities.\\n\\n7. **Acceptance and Appreciation:** Some philosophical schools of thought suggest that the meaning of life is not something to be found or created but rather to accept and appreciate the beauty and mystery of existence as it is.\\n\\nIt's important to remember that the search for the meaning of life is a deeply personal journey. What brings purpose to one person's life might differ significantly from another's. Exploring different philosophies, engaging in self-reflection, and having meaningful conversations with others can all contribute to a deeper understanding of this complex question.\""
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Philosophical Reflection\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:43:33.635829300Z",
     "start_time": "2025-02-12T23:41:21.629535700Z"
    }
   },
   "id": "746390736250fcdb"
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    22 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   477 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  150274.00 ms /   499 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Absolutely! Feeling overwhelmed is a common experience, but there are several strategies you can use to manage and reduce stress. Here are some helpful tips:\\n\\n1. **Identify the Source**: Take a moment to understand what\\'s causing your stress. Is it work, personal relationships, financial worries, or something else? Identifying the source can help you address the issue more effectively.\\n\\n2. **Practice Deep Breathing**: Deep breathing exercises can activate your body\\'s relaxation response. Try the 4-7-8 technique: Inhale deeply through your nose for a count of 4, hold your breath for a count of 7, and exhale slowly through your mouth for a count of 8.\\n\\n3. **Exercise Regularly**: Physical activity releases endorphins, which can improve your mood and reduce stress. Even a short walk, a yoga session, or some stretching can make a difference.\\n\\n4. **Get Enough Sleep**: Lack of sleep can increase stress levels. Aim for 7-9 hours of quality sleep each night. Establish a bedtime routine to signal to your body that it\\'s time to wind down.\\n\\n5. **Eat a Balanced Diet**: Nutrition plays a significant role in managing stress. Eat plenty of fruits, vegetables, whole grains, lean proteins, and healthy fats. Avoid excessive caffeine and sugar, as they can heighten stress levels.\\n\\n6. **Practice Mindfulness or Meditation**: Mindfulness involves focusing on the present moment without judgment. Meditation can help calm your mind and reduce stress. There are many apps and online resources available to guide you through these practices.\\n\\n7. **Set Boundaries**: Learn to say \"no\" when necessary. Avoid overcommitting yourself, as this can lead to increased stress. Prioritize your tasks and delegate when possible.\\n\\n8. **Connect with Others**: Social support is crucial for managing stress. Reach out to friends, family, or a support group. Talking about your feelings with someone you trust can be very helpful.\\n\\n9. **Engage in Hobbies**: Make time for activities you enjoy. Hobbies can provide a much-needed break from stressors and help you relax.\\n\\n10. **Manage Your Time**: Prioritize tasks and break them down into manageable chunks. Create a schedule or to-do list to stay organized and reduce feelings of being overwhelmed.\\n\\n11.'"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Psychological Support\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"I'm feeling a little overwhelmed. Can you offer some advice on how to cope with stress?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:46:03.832718Z",
     "start_time": "2025-02-12T23:43:33.519140600Z"
    }
   },
   "id": "a64f82e863b59950"
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    13 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    87 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   24903.59 ms /   100 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Sure, here's a short rhyme about the sea:\\n\\nIn the vast expanse of the blue,\\nThe sea whispers its ancient hue,\\nA symphony of waves that dance,\\nIn the moonlight's romantic glance.\\n\\nIts depths hold secrets yet untold,\\nOf treasures and creatures brave and bold,\\nA mirror to the sky above,\\nReflecting life, love, and the sea's love.\""
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rhyming Response (Poetry)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you write a short rhyme about the sea?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:46:28.775774700Z",
     "start_time": "2025-02-12T23:46:03.825735100Z"
    }
   },
   "id": "a17d72c479072a79"
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 14 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     8 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   473 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  143112.04 ms /   481 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, look up at the sky, see the cosmic display,\\nBillions of stars shining, like a celestial array.\\nFrom our little corner, we observe and we dream,\\nAbout the mysteries hidden in the vastest of beams.\\n\\nEach star's a sun, burning bright, in its own right,\\nSome distant and cold, others close, burning with light.\\nThey dance in the dark, like diamonds in the night,\\nGuiding sailors home, with their twinkling, soft light.\\n\\n(Chorus)\\nStars, stars, shining so bright,\\nIn the infinite darkness, they ignite.\\nFrom the Big Bang's echo, they took their place,\\nGuiding us forward, in our cosmic race.\\n\\n(Verse 2)\\nIn constellations, they form shapes, for us to see,\\nOrion's Belt, the Plough, and the Great Bear, can't you see?\\nAstrologers read their signs, and fortunes they tell,\\nBut science knows better, it's physics that reveals.\\n\\nThey're not magical, but powerful, with gravity's pull,\\nForming galaxies, with their mass, a cosmic bull.\\nSome are superdense, like neutron stars, so small,\\nYet their gravity's immense, it's a wonder to all.\\n\\n(Bridge)\\nBlack holes too, in their shadows, suck in everything,\\nLight itself can't escape, their gravitational ring.\\nBut don't be afraid, for stars will never cease,\\nThey'll keep shining on, in their cosmic peace.\\n\\n(Chorus)\\nStars, stars, shining so bright,\\nIn the infinite darkness, they ignite.\\nFrom the first stars that formed, to the end of time,\\nThey'll be our beacon, in the cosmic climb.\\n\\n(Outro)\\nSo look up, and wonder, at the stars that gleam and glow,\\nThey're more than just points of light, they're a cosmic show.\\nThe universe's story, in their twinkling, they tell,\\nStars, shining bright, forevermore, on and on they dwell.\""
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rap Lyrics (Creative Writing)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you rap about the stars?\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:48:51.932556700Z",
     "start_time": "2025-02-12T23:46:28.753805700Z"
    }
   },
   "id": "b61c1c53145b9f35"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρατηρούμε ότι σε όλες τις περιπτώσεις, οι απαντήσεις που δίνει το μοντέλο όπως και το προηγούμενο είναι συντακτικά ακριβείς (εφόσον είναι σαφείς, καλά δομημένες και σωστές γραμματικά), εννοιολογικά ακριβείς (εφόσον οι πληροφορίες που δίνει είναι εύστοχες και ισχύουν) και έχουν συνοχή (εφόσον ταιριάζουν με την ερώτηση του χρήστη και οι προτάσεις συνδέονται λογικά η μία με την άλλη)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0f0d259946cab71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 5 Εναλλακτικά μοντέλα (Ελληνικά) ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e89439f7b03edee"
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   480 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  146117.89 ms /   499 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ναι, φυσικά! Η φωτοσύνθεση είναι μια βιολογική διαδικασία που πραγματοποιείται από φυτά, άλγες και ορισμένα βακτήρια, τα οποία μετατρέπουν το φως σε χημική ενέργεια, δημιουργώντας οργανική ύλη. Αυτή η διαδικασία είναι ζωτικής σημασίας για τη διατήρηση της ζωής στον πλανήτη μας, καθώς είναι η κύρια πηγή ενέργειας για τους οργανισμούς και ο κύριος τρόπος με τον οποίο παράγεται οξυγόνο στην ατμόσφαιρα.\\n\\nΕδώ είναι μια απλοποιημένη εξήγηση του τρόπου λειτουργίας της φωτοσύνθεσης:\\n\\n1. **Απορρόφηση Φωτός**: Η διαδικασία ξεκινά όταν τα φυτά απορροφούν φως, συνήθως από το ηλιακό φως. Τα φύλλα των φυτών περιέχουν χρωστικές ουσίες, όπως η χλωροφύλλη, οι οποίες απορροφούν τα φωτόνια του φωτός.\\n\\n2. **Φωτοσυστηματική Αντίδραση**: Το απορροφημένο φως χρησιμοποιείται για να ξεκινήσει μια σειρά χημικών αντιδράσεων μέσα στα κύτταρα των φυτών. Αυτές οι αντιδράσεις χωρίζονται σε δύο φάσεις: τη φωτεινή αντίδραση (φωτοσύστημα II) και τη σκοτεινή αντίδραση (φωτοσύστημα I).\\n\\n   - **Φωτεινή Αντίδραση**: Σε αυτή τη φάση, το φως χρησιμοποιείται για να χωρίσει τα μόρια του νερού (H2O) σε υδρογόνο, οξυγόνο και ηλεκτρόνια. Το οξυγόνο απελευθερώνεται στην ατμόσφαιρα ως παραπροϊόν, το οποίο είναι ζωτικής σημασίας για την αναπνοή των ζώων και των ανθρώπων. Τα ηλεκτρόνια και το υδρογόνο στη συνέχεια σε περαιτέρω αντιδράσεις.\\n\\n   - **Σκοτεινή Αντίδραση (Κύκλος του Calvin)**: Αυτή η φάση δεν εξαρτάται άμεσα από το φως και μπορεί να συμβεί οποιαδήποτε στιγμή. Εδώ, το διοξείδιο του άνθρακα (CO2) από την ατμόσφαιρα συνδυάζεται με το υδρογόνο και τα ηλεκτρόνια από τη φωτεινή αντίδραση για να σχηματίσει γλυκόζη, η οποία είναι μια μορφή σακχάρου. Αυτή η αντίδραση περιλαμβάνει μια σειρά ενζυμικών αντιδράσεων που οδηγούν στην παραγωγή οργανικών ενώσεων.\\n\\n3. **Παραγωγή Ενέργειας και Οργανικής Ύλης**: Η γλυκόζη που παράγεται μπορεί να χρησιμοποιηθεί άμεσα από το'"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Explaining Scientific Concepts\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να εξηγήσεις πώς λειτουργεί η φωτοσύνθεση;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:51:18.045290600Z",
     "start_time": "2025-02-12T23:48:51.892663Z"
    }
   },
   "id": "6a53dc59424f3ae"
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 17 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    17 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   477 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  150063.81 ms /   494 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ναι, θα χαρώ πολύ να σας βοηθήσω να ξεκινήσετε με την εκμάθηση της προγραμματισμού σε Python! Η Python είναι μια δημοφιλής και ευέλικτη γλώσσα προγραμματισμού που χρησιμοποιείται ευρέως σε διάφορους τομείς, όπως η επιστήμη των δεδομένων, ο αυτοματισμός εργασιών, η ανάπτυξη ιστού και πολλά άλλα.\\n\\nΕδώ είναι μερικά βήματα και πόροι για να ξεκινήσετε:\\n\\n1. **Κατεβάστε και Εγκαταστήστε το Python:**\\n   - Επισκεφτείτε την επίσημη ιστοσελίδα της Python: [python.org](https://www.python.org/).\\n   - Κατεβάστε την τελευταία έκδοση του Python που ταιριάζει στο λειτουργικό σας σύστημα (Windows, macOS, Linux).\\n   - Ακολουθήστε τις οδηγίες εγκατάστασης. Μετά την εγκατάσταση, βεβαιωθείτε ότι το Python είναι προσβάσιμο από τη γραμμή εντολών ή το τερματικό σας.\\n\\n2. **Επιλογή Επεξεργαστή Κώδικα (Code Editor):**\\n   - Ένας επεξεργαστής κώδικα είναι ένα λογισμικό που σας επιτρέπει να γράφετε, να επεξεργάζεστε και να εκτελείτε κώδικα. Για αρχάριους, προτείνω επεξεργαστές όπως το Visual Studio Code, το PyCharm, ή το Jupyter Notebook. Αυτά τα εργαλεία προσφέρουν ευκολία χρήσης και ενσωματωμένες δυνατότητες για Python.\\n\\n3. **Βασικές Έννοιες της Python:**\\n   - **Σύνταξη:** Η Python έχει απλή και διαβάζουσα σύνταξη. Οι εντολές χωρίζονται συνήθως με κενά και η δομή του κώδικα είναι ευανάγνωστη.\\n   - **Μεταβλητές:** Μπορείτε να αποθηκεύσετε δεδομένα σε μεταβλητές. Για παράδειγμα: `x = 10`.\\n   - **Τύποι Δεδομένων:** Η Python υποστηρίζει διάφορους τύπους δεδομένων, όπως ακέραιους (`int`), πραγματικούς (`float`), συμβολοσειρές (`str`), λίστες (`list`), λεξικά (`dict`), κ.λπ.\\n   - **Εισαγωγή Βιβλιοθηκών:** Η Python διαθέτει μια τεράστια συλλογή από βιβλιοθήκες (modules) που προσθέτουν λειτουργικότητα. Μπορείτε να εισά'"
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Learning (Writing Code)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να με βοηθήσεις να μάθω πώς να προγραμματίζω σε Python;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:53:48.139638900Z",
     "start_time": "2025-02-12T23:51:18.034319600Z"
    }
   },
   "id": "8a1730a16939a8f4"
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    11 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   123 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   39881.72 ms /   134 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ως τεχνητή νοημοσύνη, δεν έχω πρόσβαση σε πραγματικό χρόνο δεδομένα, όπως οι τρέχουσες καιρικές συνθήκες. Για να μάθετε τον καιρό σήμερα, σας προτείνω να συμβουλευτείτε μια αξιόπιστη πηγή καιρού, όπως:\\n\\n- Μια εφαρμογή καιρού στο κινητό σας τηλέφωνο.\\n- έναν ιστότοπο καιρού.\\n- έναν μετεωρολογικό σταθμό στην περιοχή σας.\\n\\nΑυτές οι πηγές θα σας παρέχουν τις πιο ακριβείς και ενημερωμένες πληροφορίες για τον καιρό στην περιοχή σας.'"
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Casual Conversation (Weather Question)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Ποιος είναι ο καιρός σήμερα;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:54:28.057677700Z",
     "start_time": "2025-02-12T23:53:48.124678100Z"
    }
   },
   "id": "c80f42fad3c1d5f0"
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    72 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   20830.60 ms /    82 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Φυσικά! Εδώ είναι ένα αστείο για σένα:\\n\\nΓιατί οι υπολογιστές δεν μπορούν ποτέ να κρυφτούν;\\n\\nΓιατί αφήνουν πάντα ίχνη (tracks) πίσω τους!\\n\\nΕλπίζω να σε έκανε να χαμογελάσεις! Αν θέλεις περισσότερα αστειάκια, απλά πες μου.'"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Joke (Casual)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Πες μου ένα αστείο!\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:54:48.922748100Z",
     "start_time": "2025-02-12T23:54:28.034739700Z"
    }
   },
   "id": "2ab9816b153be349"
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    12 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   487 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  157110.74 ms /   499 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Το νόημα της ζωής είναι ένα βαθύ φιλοσοφικό και υπαρξιακό ερώτημα που έχει απασχολήσει τους ανθρώπους για αιώνες, και δεν υπάρχει μια μοναδική ή καθολικά αποδεκτή απάντηση. Το νόημα της ζωής είναι ένα προσωπικό και υποκειμενικό θέμα, το οποίο μπορεί να διαφέρει από άτομο σε άτομο.\\n\\nΟρισμένοι άνθρωποι βρίσκουν νόημα στη ζωή μέσα από διάφορες πτυχές, όπως:\\n\\n1. **Σχέσεις και Συνδέσεις:** Οι ανθρώπινες σχέσεις, η αγάπη, η φιλία και η οικογένεια μπορούν να δώσουν ένα βαθύ αίσθημα σκοπού. Η φροντίδα για άλλους, η δημιουργία δεσμών και η συμβολή σε μια κοινότητα μπορεί να είναι εξαιρετικά ικανοποιητική.\\n\\n2. **Προσωπική Ανάπτυξη και Αυτοπραγμάτωση:** Πολλοί άνθρωποι βρίσκουν νόημα στην προσωπική ανάπτυξη, στην ανακάλυψη των ταλέντων και των δυνατοτήτων τους, και στην επίτευξη προσωπικών στόχων. Η συνεχής μάθηση, η ανάπτυξη δεξιοτήτων και η επίτευξη ορόσημων στην καριέρα ή τα χόμπι μπορεί να είναι πηγή ικανοποίησης.\\n\\n3. **Συμβολή και Επίδραση:** Κάποιοι βρίσκουν νόημα στο να κάνουν θετική επίδραση στον κόσμο γύρω τους. Αυτό μπορεί να περιλαμβάνει εθελοντική εργασία, φιλανθρωπία, προώθηση κοινωνικών αιτημάτων ή συνεισφορά στην κοινωνία με κάποιο τρόπο. Η αίσθηση ότι κάνεις τη διαφορά μπορεί να είναι εξαιρετικά ικανοποιητική.\\n\\n4. **Πνευματικότητα και Αναζήτηση:** Για ορισμένους, το νόημα της ζωής συνδέεται με πνευματικές ή θρησκευτικές πεποιθήσεις. Η αναζήτηση μιας υψηλότερης δύναμης, η εξάσκηση πνευματικών πρακτικών ή η αναζήτηση εσωτερικής ειρήνης μπορεί να προσφέρει ένα αίσθημα σκοπού.\\n\\n5. **Απολαύσεις και Εμπειρίες:** Για μερικούς, το νόημα βρίσκεται στις απλές απολαύσεις της ζωής, όπως η εξερεύνηση της τέχνης, η απόλαυση της φύσης, η μουσική, η λογοτεχνία ή άλλες μορφές πολιτισμού. Η δημιουργία θετικών εμπειριών και η εκτίμηση των μικρών χαρών της ζωής μπορεί να είναι ικανοποιητική.\\n\\n6. **Δημιουργικότητα και Έκφραση:** Η έκφραση του εαυτού μέσω της'"
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Philosophical Reflection\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Ποιο είναι το νόημα της ζωής;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T23:57:26.073602400Z",
     "start_time": "2025-02-12T23:54:48.893825100Z"
    }
   },
   "id": "f62fc53e88393c"
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   466 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  161492.68 ms /   499 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Φυσικά! Το άγχος είναι μια κοινή αντίδραση σε διάφορες καταστάσεις της ζωής, αλλά υπάρχουν στρατηγικές που μπορείτε να εφαρμόσετε για να το διαχειριστείτε αποτελεσματικά. Εδώ είναι μερικές συμβουλές για να σας βοηθήσουν να αντιμετωπίσετε το άγχος:\\n\\n1. **Αναγνώριση και Αποδοχή:** Αναγνωρίστε ότι νιώθετε άγχος και αποδεχτείτε αυτό το συναίσθημα. Το να αγνοήσετε ή να καταπιέσετε το άγχος μπορεί να το επιδεινώσει. Δείξτε κατανόηση στον εαυτό σας και αναγνωρίστε ότι είναι φυσιολογικό να αισθάνεστε έτσι.\\n\\n2. **Αναπνοές και Χαλάρωση:** Η εστιασμένη αναπνοή είναι ένας ισχυρός τρόπος για να ηρεμήσετε το σώμα και το μυαλό σας. Δοκιμάστε τεχνικές αναπνοής, όπως η βαθιά αναπνοή από τη μύτη για μερικά δευτερόλεπτα, κρατώντας την αναπνοή σας για λίγο, και μετά αργή εκπνοή από το στόμα. Αυτό μπορεί να βοηθήσει στη μείωση του σωματικού άγχους. Επίσης, δοκιμάστε ασκήσεις χαλάρωσης των μυών ή τεχνικές διαλογισμού.\\n\\n3. **Προσδιορισμός των Αιτιών:** Προσπαθήστε να κατανοήσετε τι προκαλεί το άγχος σας. Είναι μια συγκεκριμένη κατάσταση, σκέψη, ή πρόκληση; Καταγράφοντας τις πηγές του άγχους σας, μπορείτε να αρχίσετε να αναπτύσσετε στρατηγικές αντιμετώπισης για κάθε περίπτωση.\\n\\n4. **Οργάνωση και Προγραμματισμός:** Ο άγχος συχνά προκύπτει από την αίσθηση ότι είστε κατακλυσμένοι. Δοκιμάστε να οργανώσετε τις υποχρεώσεις σας και να δημιουργήσετε ένα ρεαλιστικό πρόγραμμα. Διασπάστε μεγάλα καθήκοντα σε μικρότερα, διαχειρίσιμα βήματα. Αυτό μπορεί να σας βοηθήσει να αισθανθείτε πιο υπό έλεγχο.\\n\\n5. **Φυσική Δραστηριότητα:** Η άσκηση είναι ένας εξαιρετικός τρόπος για να μειώσετε το'"
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Psychological Support\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Νιώθω λίγο αγχωμένος. Μπορείς να προσφέρεις συμβουλές για το πώς να διαχειριστώ το άγχος;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T00:00:07.610251100Z",
     "start_time": "2025-02-12T23:57:26.036704300Z"
    }
   },
   "id": "b8926822f2b83f2f"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 12 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    19 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   135 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   43291.52 ms /   154 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Βεβαίως! Εδώ είναι μια μικρή ρίμα για τη θάλασσα:\\n\\nΣτη θάλασσα, το μπλε απλώνεται,\\nΜε κύματα που χορεύουν, μια ομορφιά ατελείωτη.\\nΤο αλάτι στον αέρα, μια αίσθηση μαγική,\\nΚαι ο ήχος των κυμάτων, μια μελωδία ηχητική.\\n\\nΕκεί, ο χρόνος μοιάζει να σταματά,\\nΣε ένα ταξίδι ονείρου, που την ψυχή αγγίζει.\\nΗ θάλασσα, μια δύναμη απέραντη,\\nΜε μυστικά βαθιά, που κανείς δεν μπορεί να μετρήσει.'"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rhyming Response (Poetry)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να γράψεις μια σύντομη ρίμα για τη θάλασσα;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T00:00:50.974959400Z",
     "start_time": "2025-02-13T00:00:07.592298900Z"
    }
   },
   "id": "1ffa30808bd88e67"
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 17 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    13 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   419 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =  111192.79 ms /   432 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Ναι, μπορώ να δημιουργήσω ένα μικρό κομμάτι ραπ αφιερωμένο στα αστέρια!\\n\\n[Ραπ αρχίζουν]\\n\\nΣτο σκοτάδι του ουρανού, μια σκηνή μαγική,\\nΑστέρια λάμπουν, σαν διαμάντια στο σκοτάδι.\\nΚάθε ένα μια ιστορία, ένα μυστήριο κρυμμένο,\\nΣτο απέραντο διάστημα, ταξιδεύουν αόρατα.\\n\\nΑπό το Μεγάλο Αστρονομικό, μέχρι το μικρό αστέρι,\\nΌλα έχουν τη θέση τους, σε αρμονία τέλεια.\\nΜε το φως τους ταξιδεύουν, μέσα στο χρόνο και το χώρο,\\nΦωτίζουν τους ονειροπόλους, που κοιτάζουν ψηλά.\\n\\nΡαπάρουν οι γαλαξίες, με ρυθμό και με μελωδία,\\nΚάθε έκρηξη σουπερνόβα, μια νέα σύνθεση.\\nΤα σκοτεινά νεφέλωμα, σαν πίνακες ζωγραφισμένοι,\\nΗ ομορφιά του σύμπαντος, σε κάθε στιγμή.\\n\\nΑστέρια, οδηγοί μας, στο ταξίδι της ζωής,\\nΦωτίζουν το μονοπάτι, όταν χάνουμε την πορεία.\\nΜε τη λάμψη τους μας καλούν, να εξερευνήσουμε,\\nΤο άπειρο, το άγνωστο, με θάρρος να αντιμετωπίσουμε.\\n\\n[Κλείσιμο]\\n\\nΚαι όταν ο ουρανός γεμίζει αστέρια,\\nΝα θυμάσαι, είμαστε μέρος αυτού του χορού.\\nΣτο σύμπαν συνδεδεμένοι, σαν μια μεγάλη οικογένεια,\\nΑς θαυμάζουμε τα αστέρια, και ας ονειρευόμαστε μαζί.\\n\\nΕλπίζω να σας άρεσε αυτό το μικρό ραπ ταξίδι στους αστέρες! Μπορώ να προσαρμόσω ή να επεκτείνω το κείμενο αν έχετε συγκεκριμένες ιδέες ή θέματα που θέλετε να συμπεριληφθούν.'"
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rap Lyrics (Creative Writing)\n",
    "llm.create_chat_completion(\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Μπορείς να κάνεις ραπ για τα αστέρια;\"}\n",
    "    ]\n",
    ")[\"choices\"][0][\"message\"][\"content\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T00:02:42.152576Z",
     "start_time": "2025-02-13T00:00:50.922100600Z"
    }
   },
   "id": "eb55f30c32f92e02"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρατηρούμε ότι σε όλες τις περιπτώσεις, οι απαντήσεις που δίνει το μοντέλο στα ελληνικά είναι συντακτικά ακριβείς, σε αντίθεση με το προηγούμενο μοντέλο (εφόσον είναι σαφείς, καλά δομημένες και σωστές γραμματικά), εννοιολογικά ακριβείς (εφόσον οι πληροφορίες που δίνει είναι εύστοχες και ισχύουν) και έχουν συνοχή (εφόσον ταιριάζουν με την ερώτηση του χρήστη και οι προτάσεις συνδέονται λογικά η μία με την άλλη)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb7cf41f7d93b0c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 6 Πολλαπλές απαντήσεις ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "45988d5ec57ff469"
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 21 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   25954.17 ms /   101 tokens\n",
      "Llama.generate: 21 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   40677.24 ms /   101 tokens\n",
      "Llama.generate: 21 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   36858.37 ms /   101 tokens\n",
      "Llama.generate: 21 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    7328.96 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   28849.85 ms /   101 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "[\"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, let's talk about the night sky, where the stars shine so bright,\\nFrom the Milky Way to the constellations, it's a cosmic sight.\\nBillions of suns, distant and near, in a dance so profound,\\nGalaxies spinning, in the vast, endless sound.\\n\\n(Chorus)\\nStars, twinkling like\",\n \"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, let's talk about the night sky, where the stars shine so bright,\\nFrom the Milky Way to the constellations, it's a cosmic sight.\\nBillions of suns, far, far away, in galaxies unseen,\\nTheir light travels for eons, just to reach our green scene.\\n\\nAlpha Centauri, our nearest neighbor, a triple star\",\n \"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, let's talk about the night sky, where the stars shine so bright,\\nFrom the Milky Way to the constellations, it's a cosmic sight.\\nBillions of suns, distant and near, in a dance so profound,\\nGalaxies spinning, in the vast, endless sound.\\n\\n(Chorus)\\nStars, twinkling like\",\n \"Absolutely, I'd be happy to create a rap about the stars! Here we go:\\n\\n(Verse 1)\\nYo, look up at the sky, where the cosmos lie,\\nBillions of stars shining, like a vast eye.\\nFrom Andromeda to the Southern Cross,\\nEach one's a sun, in its own space.\\n\\nThey dance in the night, in a celestial waltz,\\nTwinkling lights, in the inky haze.\\nDistant\"]"
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Rap Lyrics (Creative Writing)\n",
    "temperatures = [0.1, 0.9] \n",
    "top_ps = [0.1, 0.9]        \n",
    "# penalties = [0.1, 0.9]\n",
    "\n",
    "responses = [\n",
    "    llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you rap about the stars?\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        # presence_penalty=penalty,\n",
    "        # frequency_penalty=penalty,\n",
    "        # repeat_penalty=penalty,\n",
    "        max_tokens=100 # apla gia na ginei h sigkrish pio eukolh sto mati\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    for temperature in temperatures  # Loop through temperatures\n",
    "    for top_p in top_ps            # Loop through top_p values\n",
    "    # for penalty in penalties\n",
    "]\n",
    "\n",
    "responses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T00:38:18.697170800Z",
     "start_time": "2025-02-13T00:36:06.282540800Z"
    }
   },
   "id": "7d1873bf820ef44c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 38 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2493.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    11 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /    99 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9309.51 ms /   110 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2493.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =    9261.13 ms /   101 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2493.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   10238.32 ms /   101 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 1 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2493.25 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /   100 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =   14712.50 ms /   101 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": "[\"Photosynthesis is a fascinating process that occurs in plants, algae, and some bacteria, where they convert light energy from the sun into chemical energy in the form of glucose. Here's a simplified explanation of how it works:\\n\\n**The Process of Photosynthesis:**\\n\\n1. **Light Absorption**: Light energy from the sun is absorbed by pigments such as chlorophyll, which is present in the thylakoid membranes of chloroplasts (organelles found in plant cells).\\n2.\",\n \"Photosynthesis is a fascinating process that occurs in plants, algae, and some bacteria, and it's essential for life on Earth. Here's a simplified explanation of how it works:\\n\\n**What is photosynthesis?**\\n\\nPhotosynthesis is the process by which plants, algae, and some bacteria convert light energy from the sun into chemical energy in the form of glucose (a type of sugar). This process also produces oxygen as a byproduct, which is released into the atmosphere.\\n\\n**The equation:**\\n\\n6\",\n \"Photosynthesis is a fascinating process that occurs in plants, algae, and some bacteria, where they convert light energy from the sun into chemical energy in the form of glucose. Here's a simplified explanation of how it works:\\n\\n**The Basic Equation:**\\n\\n6 CO2 (carbon dioxide) + 6 H2O (water) + light energy → C6H12O6 (glucose) + 6 O2 (oxygen)\\n\\n**The Process:**\\n\\n1. **Light Absorption\",\n \"Photosynthesis is a fascinating process that occurs in plants, algae, and some bacteria. It's the basis of life on Earth, as it provides energy and organic compounds for these organisms. Here's a step-by-step explanation of how photosynthesis works:\\n\\n**What is Photosynthesis?**\\n\\nPhotosynthesis is a complex process that converts light energy from the sun into chemical energy in the form of glucose, a type of sugar. This process also produces oxygen as a byproduct.\\n\\n**The Photosynthesis Equation**\\n\\n\"]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Category: Explaining Scientific Concepts\n",
    "temperatures = [0.1, 0.9] \n",
    "top_ps = [0.1, 0.9]        \n",
    "# penalties = [0.1, 0.9]\n",
    "\n",
    "responses = [\n",
    "    llm.create_chat_completion(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you explain how photosynthesis works?\"}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        # presence_penalty=penalty,\n",
    "        # frequency_penalty=penalty,\n",
    "        # repeat_penalty=penalty,\n",
    "        max_tokens=100 # apla gia na ginei h sigkrish pio eukolh sto mati\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    for temperature in temperatures  # Loop through temperatures\n",
    "    for top_p in top_ps            # Loop through top_p values\n",
    "    # for penalty in penalties\n",
    "]\n",
    "\n",
    "responses"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-12T18:34:05.619726100Z",
     "start_time": "2025-02-12T18:33:22.012513600Z"
    }
   },
   "id": "2e0d3da238be9483"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Καλώντας πολλές φορες την create_chat_completion εκτυπώονται εναλλακτικές απαντήσεις για το ίδιο ερώτημα. Αυτή η συμπεριφορά ελέγχεται από συγκεκριμένες παραμέτρους στη διαμόρφωση του μοντέλου, οι οποίες εισάγουν μεταβλητότητα στην έξοδο. \n",
    "Αρχικά, η παράμετρος θερμοκρασία ελέγχει την τυχαιότητα των απαντήσεων του μοντέλου.\n",
    "Μια υψηλότερη θερμοκρασία (πιο κοντά στο 1) ενθαρρύνει πιο διαφορετικές και δημιουργικές απαντήσεις. Το μοντέλο θα παράγει λιγότερο προβλέψιμες απαντήσεις, διερευνώντας ένα ευρύτερο φάσμα δυνατοτήτων.\n",
    "Μια χαμηλότερη θερμοκρασία (πιο κοντά στο 0) κάνει την έξοδο πιο ντετερμινιστική και εστιασμένη, παράγοντας πιο επαναλαμβανόμενες ή συνεπείς απαντήσεις.\n",
    "Επιπλέον, η παράμετρος top_p ελέγχει την ποικιλία των απαντήσεων επιλέγοντας από τα πιο πιθανά επόμενα tokens.\n",
    "Εάν το top_p έχει οριστεί σε 1,0, το μοντέλο είναι ελεύθερο να λάβει δείγμα από όλα τα tokens.\n",
    "Εάν το top_p είναι μικρότερο (π.χ. 0,9), περιορίζει τη δειγματοληψία σε ένα πιο στενό σύνολο πιθανών token, μειώνοντας την τυχαιότητα και εστιάζοντας περισσότερο σε επιλογές υψηλής πιθανότητας.\n",
    "Τέλος, άλλοι παράμετροι είναι τα presence/frequency/repeat penalty που έχουν ως αποτέλεσμα κάποια token να μην επιλεχθούν με βάση το penalty (το presence penalty είναι σταθερό εάν το token έχει εμφανιστεί τουλάχιστον μία φορά στο παρελθόν, ενώ το frequency penalty είναι μεγαλύτερο εάν το token έχει εμφανιστεί πολλές φορές σε όλο το κείμενο. To repeat penalty έχει να κάνει με local repetition των token σε μια ακολουθία λέξεων.)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c28db7d5734624"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---------- 7 Bonus: Χρήση embeddings από LLMs ----------"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eb72fda91334c22"
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 35 key-value pairs and 255 tensors from C:\\Users\\User\\.cache\\huggingface\\hub\\models--MaziyarPanahi--Llama-3.2-3B-Instruct-GGUF\\snapshots\\e56a0ae870579697698c3ded68df97747125d554\\.\\Llama-3.2-3B-Instruct.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Models Meta Llama Llama 3.2 3B Instruct\n",
      "llama_model_loader: - kv   3:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   4:                           general.basename str              = models-meta-llama-Llama-3.2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 3B\n",
      "llama_model_loader: - kv   6:                            general.license str              = llama3.2\n",
      "llama_model_loader: - kv   7:                               general.tags arr[str,6]       = [\"facebook\", \"meta\", \"pytorch\", \"llam...\n",
      "llama_model_loader: - kv   8:                          general.languages arr[str,8]       = [\"en\", \"de\", \"fr\", \"it\", \"pt\", \"hi\", ...\n",
      "llama_model_loader: - kv   9:                          llama.block_count u32              = 28\n",
      "llama_model_loader: - kv  10:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv  11:                     llama.embedding_length u32              = 3072\n",
      "llama_model_loader: - kv  12:                  llama.feed_forward_length u32              = 8192\n",
      "llama_model_loader: - kv  13:                 llama.attention.head_count u32              = 24\n",
      "llama_model_loader: - kv  14:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  15:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  16:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  17:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  18:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  19:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  20:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  21:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  22:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  23:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  26:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  28:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  29:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - kv  30:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  31:                      quantize.imatrix.file str              = ./Llama-3.2-3B-Instruct-GGUF_imatrix.dat\n",
      "llama_model_loader: - kv  32:                   quantize.imatrix.dataset str              = group_40.txt\n",
      "llama_model_loader: - kv  33:             quantize.imatrix.entries_count i32              = 196\n",
      "llama_model_loader: - kv  34:              quantize.imatrix.chunks_count i32              = 68\n",
      "llama_model_loader: - type  f32:   58 tensors\n",
      "llama_model_loader: - type q4_K:  168 tensors\n",
      "llama_model_loader: - type q6_K:   29 tensors\n",
      "llm_load_vocab: control token: 128098 '<|reserved_special_token_90|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128191 '<|reserved_special_token_183|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128130 '<|reserved_special_token_122|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128119 '<|reserved_special_token_111|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128136 '<|reserved_special_token_128|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128155 '<|reserved_special_token_147|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128196 '<|reserved_special_token_188|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128101 '<|reserved_special_token_93|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128138 '<|reserved_special_token_130|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128181 '<|reserved_special_token_173|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128034 '<|reserved_special_token_26|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128209 '<|reserved_special_token_201|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128031 '<|reserved_special_token_23|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128050 '<|reserved_special_token_42|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128244 '<|reserved_special_token_236|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128148 '<|reserved_special_token_140|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128198 '<|reserved_special_token_190|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128229 '<|reserved_special_token_221|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128165 '<|reserved_special_token_157|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128246 '<|reserved_special_token_238|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128017 '<|reserved_special_token_9|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128216 '<|reserved_special_token_208|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128161 '<|reserved_special_token_153|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128224 '<|reserved_special_token_216|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128082 '<|reserved_special_token_74|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128004 '<|finetune_right_pad_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128249 '<|reserved_special_token_241|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128107 '<|reserved_special_token_99|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128079 '<|reserved_special_token_71|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128225 '<|reserved_special_token_217|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128175 '<|reserved_special_token_167|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128223 '<|reserved_special_token_215|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128182 '<|reserved_special_token_174|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128068 '<|reserved_special_token_60|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128252 '<|reserved_special_token_244|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128178 '<|reserved_special_token_170|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128221 '<|reserved_special_token_213|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128052 '<|reserved_special_token_44|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128122 '<|reserved_special_token_114|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128151 '<|reserved_special_token_143|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128121 '<|reserved_special_token_113|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128158 '<|reserved_special_token_150|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128096 '<|reserved_special_token_88|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128090 '<|reserved_special_token_82|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128238 '<|reserved_special_token_230|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128139 '<|reserved_special_token_131|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128176 '<|reserved_special_token_168|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128077 '<|reserved_special_token_69|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128214 '<|reserved_special_token_206|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128171 '<|reserved_special_token_163|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128112 '<|reserved_special_token_104|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128180 '<|reserved_special_token_172|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128060 '<|reserved_special_token_52|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128152 '<|reserved_special_token_144|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128116 '<|reserved_special_token_108|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128072 '<|reserved_special_token_64|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128059 '<|reserved_special_token_51|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128094 '<|reserved_special_token_86|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128187 '<|reserved_special_token_179|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128103 '<|reserved_special_token_95|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128127 '<|reserved_special_token_119|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128023 '<|reserved_special_token_15|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128037 '<|reserved_special_token_29|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128228 '<|reserved_special_token_220|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128091 '<|reserved_special_token_83|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128044 '<|reserved_special_token_36|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128218 '<|reserved_special_token_210|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128211 '<|reserved_special_token_203|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128073 '<|reserved_special_token_65|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128168 '<|reserved_special_token_160|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128183 '<|reserved_special_token_175|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128234 '<|reserved_special_token_226|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128235 '<|reserved_special_token_227|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128067 '<|reserved_special_token_59|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128039 '<|reserved_special_token_31|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128106 '<|reserved_special_token_98|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128250 '<|reserved_special_token_242|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128173 '<|reserved_special_token_165|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128126 '<|reserved_special_token_118|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128047 '<|reserved_special_token_39|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128240 '<|reserved_special_token_232|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128045 '<|reserved_special_token_37|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128195 '<|reserved_special_token_187|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128078 '<|reserved_special_token_70|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128137 '<|reserved_special_token_129|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128186 '<|reserved_special_token_178|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128048 '<|reserved_special_token_40|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128076 '<|reserved_special_token_68|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128029 '<|reserved_special_token_21|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128013 '<|reserved_special_token_5|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128197 '<|reserved_special_token_189|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128056 '<|reserved_special_token_48|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128123 '<|reserved_special_token_115|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128095 '<|reserved_special_token_87|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128089 '<|reserved_special_token_81|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128057 '<|reserved_special_token_49|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128163 '<|reserved_special_token_155|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128011 '<|reserved_special_token_3|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128053 '<|reserved_special_token_45|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128160 '<|reserved_special_token_152|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128222 '<|reserved_special_token_214|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128035 '<|reserved_special_token_27|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128162 '<|reserved_special_token_154|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128205 '<|reserved_special_token_197|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128109 '<|reserved_special_token_101|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128185 '<|reserved_special_token_177|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128114 '<|reserved_special_token_106|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128159 '<|reserved_special_token_151|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128179 '<|reserved_special_token_171|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128115 '<|reserved_special_token_107|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128087 '<|reserved_special_token_79|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128113 '<|reserved_special_token_105|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128054 '<|reserved_special_token_46|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128030 '<|reserved_special_token_22|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128170 '<|reserved_special_token_162|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128012 '<|reserved_special_token_4|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128064 '<|reserved_special_token_56|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128118 '<|reserved_special_token_110|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128206 '<|reserved_special_token_198|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128099 '<|reserved_special_token_91|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128133 '<|reserved_special_token_125|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128190 '<|reserved_special_token_182|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128097 '<|reserved_special_token_89|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128086 '<|reserved_special_token_78|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128120 '<|reserved_special_token_112|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128193 '<|reserved_special_token_185|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128049 '<|reserved_special_token_41|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128242 '<|reserved_special_token_234|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128142 '<|reserved_special_token_134|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128188 '<|reserved_special_token_180|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128144 '<|reserved_special_token_136|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128247 '<|reserved_special_token_239|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128065 '<|reserved_special_token_57|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128117 '<|reserved_special_token_109|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128033 '<|reserved_special_token_25|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128184 '<|reserved_special_token_176|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128040 '<|reserved_special_token_32|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128204 '<|reserved_special_token_196|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128210 '<|reserved_special_token_202|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128245 '<|reserved_special_token_237|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128135 '<|reserved_special_token_127|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128071 '<|reserved_special_token_63|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128153 '<|reserved_special_token_145|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128194 '<|reserved_special_token_186|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128177 '<|reserved_special_token_169|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128236 '<|reserved_special_token_228|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128248 '<|reserved_special_token_240|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128241 '<|reserved_special_token_233|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128212 '<|reserved_special_token_204|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128207 '<|reserved_special_token_199|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128005 '<|reserved_special_token_2|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128010 '<|python_tag|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128014 '<|reserved_special_token_6|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128015 '<|reserved_special_token_7|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128016 '<|reserved_special_token_8|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128018 '<|reserved_special_token_10|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128019 '<|reserved_special_token_11|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128020 '<|reserved_special_token_12|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128021 '<|reserved_special_token_13|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128022 '<|reserved_special_token_14|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128024 '<|reserved_special_token_16|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128025 '<|reserved_special_token_17|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128026 '<|reserved_special_token_18|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128027 '<|reserved_special_token_19|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128028 '<|reserved_special_token_20|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128032 '<|reserved_special_token_24|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128036 '<|reserved_special_token_28|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128038 '<|reserved_special_token_30|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128041 '<|reserved_special_token_33|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128042 '<|reserved_special_token_34|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128043 '<|reserved_special_token_35|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128046 '<|reserved_special_token_38|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128051 '<|reserved_special_token_43|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128055 '<|reserved_special_token_47|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128058 '<|reserved_special_token_50|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128061 '<|reserved_special_token_53|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128062 '<|reserved_special_token_54|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128063 '<|reserved_special_token_55|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128066 '<|reserved_special_token_58|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128069 '<|reserved_special_token_61|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128070 '<|reserved_special_token_62|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128074 '<|reserved_special_token_66|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128075 '<|reserved_special_token_67|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128080 '<|reserved_special_token_72|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128081 '<|reserved_special_token_73|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128083 '<|reserved_special_token_75|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128084 '<|reserved_special_token_76|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128085 '<|reserved_special_token_77|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128088 '<|reserved_special_token_80|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128092 '<|reserved_special_token_84|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128093 '<|reserved_special_token_85|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128100 '<|reserved_special_token_92|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128102 '<|reserved_special_token_94|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128104 '<|reserved_special_token_96|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128105 '<|reserved_special_token_97|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128108 '<|reserved_special_token_100|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128110 '<|reserved_special_token_102|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128111 '<|reserved_special_token_103|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128124 '<|reserved_special_token_116|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128125 '<|reserved_special_token_117|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128128 '<|reserved_special_token_120|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128129 '<|reserved_special_token_121|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128131 '<|reserved_special_token_123|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128132 '<|reserved_special_token_124|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128134 '<|reserved_special_token_126|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128140 '<|reserved_special_token_132|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128141 '<|reserved_special_token_133|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128143 '<|reserved_special_token_135|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128145 '<|reserved_special_token_137|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128146 '<|reserved_special_token_138|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128147 '<|reserved_special_token_139|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128149 '<|reserved_special_token_141|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128150 '<|reserved_special_token_142|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128154 '<|reserved_special_token_146|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128156 '<|reserved_special_token_148|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128157 '<|reserved_special_token_149|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128164 '<|reserved_special_token_156|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128166 '<|reserved_special_token_158|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128167 '<|reserved_special_token_159|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128169 '<|reserved_special_token_161|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128172 '<|reserved_special_token_164|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128174 '<|reserved_special_token_166|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128189 '<|reserved_special_token_181|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128192 '<|reserved_special_token_184|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128199 '<|reserved_special_token_191|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128200 '<|reserved_special_token_192|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128201 '<|reserved_special_token_193|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128202 '<|reserved_special_token_194|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128203 '<|reserved_special_token_195|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128208 '<|reserved_special_token_200|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128213 '<|reserved_special_token_205|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128215 '<|reserved_special_token_207|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128217 '<|reserved_special_token_209|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128219 '<|reserved_special_token_211|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128220 '<|reserved_special_token_212|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128226 '<|reserved_special_token_218|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128227 '<|reserved_special_token_219|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128230 '<|reserved_special_token_222|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128231 '<|reserved_special_token_223|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128232 '<|reserved_special_token_224|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128233 '<|reserved_special_token_225|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128237 '<|reserved_special_token_229|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128239 '<|reserved_special_token_231|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128243 '<|reserved_special_token_235|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128251 '<|reserved_special_token_243|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128253 '<|reserved_special_token_245|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128254 '<|reserved_special_token_246|>' is not marked as EOG\n",
      "llm_load_vocab: control token: 128255 '<|reserved_special_token_247|>' is not marked as EOG\n",
      "llm_load_vocab: special tokens cache size = 256\n",
      "llm_load_vocab: token to piece cache size = 0.7999 MB\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = BPE\n",
      "llm_load_print_meta: n_vocab          = 128256\n",
      "llm_load_print_meta: n_merges         = 280147\n",
      "llm_load_print_meta: vocab_only       = 0\n",
      "llm_load_print_meta: n_ctx_train      = 131072\n",
      "llm_load_print_meta: n_embd           = 3072\n",
      "llm_load_print_meta: n_layer          = 28\n",
      "llm_load_print_meta: n_head           = 24\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_swa            = 0\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 3\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 8192\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 500000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_ctx_orig_yarn  = 131072\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
      "llm_load_print_meta: model type       = 3B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 3.21 B\n",
      "llm_load_print_meta: model size       = 1.87 GiB (5.01 BPW) \n",
      "llm_load_print_meta: general.name     = Models Meta Llama Llama 3.2 3B Instruct\n",
      "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
      "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: EOM token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: LF token         = 128 'Ä'\n",
      "llm_load_print_meta: EOG token        = 128008 '<|eom_id|>'\n",
      "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
      "llm_load_print_meta: max token length = 256\n",
      "llm_load_tensors: tensor 'token_embd.weight' (q6_K) (and 282 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "llm_load_tensors:   CPU_Mapped model buffer size =  1918.35 MiB\n",
      "....................................................................................\n",
      "llama_new_context_with_model: n_seq_max     = 1\n",
      "llama_new_context_with_model: n_ctx         = 512\n",
      "llama_new_context_with_model: n_ctx_per_seq = 512\n",
      "llama_new_context_with_model: n_batch       = 512\n",
      "llama_new_context_with_model: n_ubatch      = 512\n",
      "llama_new_context_with_model: flash_attn    = 0\n",
      "llama_new_context_with_model: freq_base     = 500000.0\n",
      "llama_new_context_with_model: freq_scale    = 1\n",
      "llama_new_context_with_model: n_ctx_per_seq (512) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 28, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =    56.00 MiB\n",
      "llama_new_context_with_model: KV self size  =   56.00 MiB, K (f16):   28.00 MiB, V (f16):   28.00 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =     0.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   256.50 MiB\n",
      "llama_new_context_with_model: graph nodes  = 902\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'Models Meta Llama Llama 3.2 3B Instruct', 'general.architecture': 'llama', 'general.type': 'model', 'llama.block_count': '28', 'general.basename': 'models-meta-llama-Llama-3.2', 'general.finetune': 'Instruct', 'general.size_label': '3B', 'general.license': 'llama3.2', 'llama.context_length': '131072', 'llama.embedding_length': '3072', 'llama.feed_forward_length': '8192', 'llama.attention.head_count': '24', 'tokenizer.ggml.eos_token_id': '128009', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.rope.freq_base': '500000.000000', 'quantize.imatrix.entries_count': '196', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.attention.key_length': '128', 'llama.attention.value_length': '128', 'llama.vocab_size': '128256', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.model': 'gpt2', 'tokenizer.ggml.pre': 'llama-bpe', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '128000', 'tokenizer.chat_template': '{{- bos_token }}\\n{%- if custom_tools is defined %}\\n    {%- set tools = custom_tools %}\\n{%- endif %}\\n{%- if not tools_in_user_message is defined %}\\n    {%- set tools_in_user_message = true %}\\n{%- endif %}\\n{%- if not date_string is defined %}\\n    {%- if strftime_now is defined %}\\n        {%- set date_string = strftime_now(\"%d %b %Y\") %}\\n    {%- else %}\\n        {%- set date_string = \"26 Jul 2024\" %}\\n    {%- endif %}\\n{%- endif %}\\n{%- if not tools is defined %}\\n    {%- set tools = none %}\\n{%- endif %}\\n\\n{#- This block extracts the system message, so we can slot it into the right place. #}\\n{%- if messages[0][\\'role\\'] == \\'system\\' %}\\n    {%- set system_message = messages[0][\\'content\\']|trim %}\\n    {%- set messages = messages[1:] %}\\n{%- else %}\\n    {%- set system_message = \"\" %}\\n{%- endif %}\\n\\n{#- System message #}\\n{{- \"<|start_header_id|>system<|end_header_id|>\\\\n\\\\n\" }}\\n{%- if tools is not none %}\\n    {{- \"Environment: ipython\\\\n\" }}\\n{%- endif %}\\n{{- \"Cutting Knowledge Date: December 2023\\\\n\" }}\\n{{- \"Today Date: \" + date_string + \"\\\\n\\\\n\" }}\\n{%- if tools is not none and not tools_in_user_message %}\\n    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n{%- endif %}\\n{{- system_message }}\\n{{- \"<|eot_id|>\" }}\\n\\n{#- Custom tools are passed in a user message with some extra guidance #}\\n{%- if tools_in_user_message and not tools is none %}\\n    {#- Extract the first user message so we can plug it in here #}\\n    {%- if messages | length != 0 %}\\n        {%- set first_user_message = messages[0][\\'content\\']|trim %}\\n        {%- set messages = messages[1:] %}\\n    {%- else %}\\n        {{- raise_exception(\"Cannot put tools in the first user message when there\\'s no first user message!\") }}\\n{%- endif %}\\n    {{- \\'<|start_header_id|>user<|end_header_id|>\\\\n\\\\n\\' -}}\\n    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\\n    {{- \"with its proper arguments that best answers the given prompt.\\\\n\\\\n\" }}\\n    {{- \\'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.\\' }}\\n    {{- \"Do not use variables.\\\\n\\\\n\" }}\\n    {%- for t in tools %}\\n        {{- t | tojson(indent=4) }}\\n        {{- \"\\\\n\\\\n\" }}\\n    {%- endfor %}\\n    {{- first_user_message + \"<|eot_id|>\"}}\\n{%- endif %}\\n\\n{%- for message in messages %}\\n    {%- if not (message.role == \\'ipython\\' or message.role == \\'tool\\' or \\'tool_calls\\' in message) %}\\n        {{- \\'<|start_header_id|>\\' + message[\\'role\\'] + \\'<|end_header_id|>\\\\n\\\\n\\'+ message[\\'content\\'] | trim + \\'<|eot_id|>\\' }}\\n    {%- elif \\'tool_calls\\' in message %}\\n        {%- if not message.tool_calls|length == 1 %}\\n            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\\n        {%- endif %}\\n        {%- set tool_call = message.tool_calls[0].function %}\\n        {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' -}}\\n        {{- \\'{\"name\": \"\\' + tool_call.name + \\'\", \\' }}\\n        {{- \\'\"parameters\": \\' }}\\n        {{- tool_call.arguments | tojson }}\\n        {{- \"}\" }}\\n        {{- \"<|eot_id|>\" }}\\n    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\\n        {{- \"<|start_header_id|>ipython<|end_header_id|>\\\\n\\\\n\" }}\\n        {%- if message.content is mapping or message.content is iterable %}\\n            {{- message.content | tojson }}\\n        {%- else %}\\n            {{- message.content }}\\n        {%- endif %}\\n        {{- \"<|eot_id|>\" }}\\n    {%- endif %}\\n{%- endfor %}\\n{%- if add_generation_prompt %}\\n    {{- \\'<|start_header_id|>assistant<|end_header_id|>\\\\n\\\\n\\' }}\\n{%- endif %}\\n', 'quantize.imatrix.chunks_count': '68', 'quantize.imatrix.file': './Llama-3.2-3B-Instruct-GGUF_imatrix.dat', 'quantize.imatrix.dataset': 'group_40.txt'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Using gguf chat template: {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- if strftime_now is defined %}\n",
      "        {%- set date_string = strftime_now(\"%d %b %Y\") %}\n",
      "    {%- else %}\n",
      "        {%- set date_string = \"26 Jul 2024\" %}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "        {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "        {{- '\"parameters\": ' }}\n",
      "        {{- tool_call.arguments | tojson }}\n",
      "        {{- \"}\" }}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "Using chat eos_token: <|eot_id|>\n",
      "Using chat bos_token: <|begin_of_text|>\n",
      "llama_perf_context_print:        load time =     626.84 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     9 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     628.09 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     626.84 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     2 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     127.97 ms /     3 tokens\n",
      "llama_perf_context_print:        load time =     626.84 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     9 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     374.37 ms /    10 tokens\n",
      "llama_perf_context_print:        load time =     626.84 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /    10 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     428.50 ms /    11 tokens\n",
      "llama_perf_context_print:        load time =     626.84 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     9 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:       total time =     338.67 ms /    10 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 0 shape: (9, 3072)\n",
      "Embedding 1 shape: (2, 3072)\n",
      "Embedding 2 shape: (9, 3072)\n",
      "Embedding 3 shape: (10, 3072)\n",
      "Embedding 4 shape: (9, 3072)\n",
      "Cosine Similarity Matrix:\n",
      "[[1.         0.43353022 0.74344546 0.69686452 0.98460014]\n",
      " [0.43353022 1.         0.41795521 0.39198452 0.43384972]\n",
      " [0.74344546 0.41795521 1.         0.71973449 0.74407319]\n",
      " [0.69686452 0.39198452 0.71973449 1.         0.69155921]\n",
      " [0.98460014 0.43384972 0.74407319 0.69155921 1.        ]]\n",
      "Norms of embeddings: [54.29385976717275, 47.02709071268502, 55.36012739126552, 53.13773393560921, 54.10123171195437]\n"
     ]
    }
   ],
   "source": [
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"MaziyarPanahi/Llama-3.2-3B-Instruct-GGUF\",\n",
    "    filename=\"Llama-3.2-3B-Instruct.Q4_K_M.gguf\",\n",
    "    embedding='true'\n",
    ")\n",
    "\n",
    "# Define the sentences\n",
    "sentences = [\n",
    "    \"The cat is sitting on the mat.\",\n",
    "    \"Damn\",\n",
    "    \"The sun is shining brightly in the sky\",\n",
    "    \"A soccer match was held at the stadium.\",\n",
    "    \"The cat is sitting on the couch!\",\n",
    "]\n",
    "\n",
    "# Get embeddings for each sentence\n",
    "embeddings = [llm.create_embedding(sentence)['data'][0]['embedding'] for sentence in sentences]\n",
    "for i, emb in enumerate(embeddings):\n",
    "    print(f\"Embedding {i} shape: {np.array(emb).shape}\")\n",
    "\n",
    "sentence_embeddings = [np.mean(np.array(emb), axis=0) for emb in embeddings]\n",
    "# sentence_embeddings = sentence_embeddings / np.linalg.norm(sentence_embeddings, axis=1, keepdims=True)\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "\n",
    "# Print the similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\")\n",
    "print(similarity_matrix)\n",
    "\n",
    "norms = [np.linalg.norm(emb) for emb in sentence_embeddings]\n",
    "print(\"Norms of embeddings:\", norms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-13T01:45:19.741142Z",
     "start_time": "2025-02-13T01:45:12.261190600Z"
    }
   },
   "id": "35c6f5e157851363"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Παρατηρούμε ότι οι προτάσεις που είναι σημασιολογικά όμοιες μεταξύ τους έχουν όμοιες ενσωματώσεις (όπως είναι η πρόταση 1 με την πρόταση 5), ωστόσο και οι προτάσεις που δεν είναι τόσο πολύ σημασιολογικά όμοιες μεταξύ τους έχουν και αυτές όμοιες ενσωματώσεις, ωστόσο σε μικρότερο βαθμό (πρόταση 1 με πρόταση 2/3/4)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed795ef32951a59"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "eacbd8f5fb45ec3a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
